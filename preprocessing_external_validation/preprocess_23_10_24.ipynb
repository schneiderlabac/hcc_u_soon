{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "install.packages(\"writexl\")\n",
    "install.packages(\"svglite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "library(writexl)\n",
    "library(readxl)\n",
    "library(ggplot2)\n",
    "library(scales)  # For comma formatting\n",
    "library(data.table)\n",
    "library(lubridate)\n",
    "library(svglite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summarize_na <- function(df_covariates, df_y = NULL, rule = FALSE) {\n",
    "  # Get total number of rows\n",
    "  total_rows <- nrow(df_covariates)\n",
    "  \n",
    "  # Initialize empty data frame\n",
    "  df_cov_amount <- data.frame(\n",
    "    covariate = character(ncol(df_covariates)),\n",
    "    missing = numeric(ncol(df_covariates)),\n",
    "    present = numeric(ncol(df_covariates)),\n",
    "    missing_in_positive = numeric(ncol(df_covariates))\n",
    "  )\n",
    "  \n",
    "  colnames(df_cov_amount) <- c(\"covariate\", \"missing\", \"present\", \"missing_in_positive\")\n",
    "  \n",
    "  # Populate the data frame\n",
    "  df_cov_amount$covariate <- colnames(df_covariates)\n",
    "  df_cov_amount$missing <- colSums(is.na(df_covariates))\n",
    "  df_cov_amount$present <- total_rows - df_cov_amount$missing\n",
    "  \n",
    "\n",
    "    \n",
    "  # Calculate missing in positive class if df_y is provided\n",
    "  if (!is.null(df_y)) {\n",
    "    df_merged <- inner_join(df_covariates, df_y, by = eid) %>% filter(status == 1)\n",
    "    df_cov_amount$missing_in_positive <- colSums(is.na(df_merged))\n",
    "  } else {\n",
    "    df_cov_amount$missing_in_positive <- NA\n",
    "  }\n",
    "  \n",
    "  if (rule) {\n",
    "    # Apply the \"<20\" rule\n",
    "    apply_rule <- function(x) {\n",
    "      ifelse(is.na(x), NA, ifelse(x < 20, \"<20\", as.character(x)))\n",
    "    }\n",
    "    \n",
    "    df_cov_amount$missing <- apply_rule(df_cov_amount$missing)\n",
    "    df_cov_amount$present <- apply_rule(df_cov_amount$present)\n",
    "    df_cov_amount$missing_in_positive <- apply_rule(df_cov_amount$missing_in_positive)\n",
    "    \n",
    "    # Convert columns to character type\n",
    "    df_cov_amount$missing <- as.character(df_cov_amount$missing)\n",
    "    df_cov_amount$present <- as.character(df_cov_amount$present)\n",
    "    df_cov_amount$missing_in_positive <- as.character(df_cov_amount$missing_in_positive)\n",
    "  }\n",
    "  \n",
    "  print(paste(\"Total rows:\", total_rows))\n",
    "  if (!is.null(df_y)) {\n",
    "    print(paste(\"Positive cases:\", sum(df_y$status == 1)))\n",
    "  }\n",
    "  if (rule) {\n",
    "    print(\"Note: Values below 20 are reported as '<20' to comply with All of Us regulations.\")\n",
    "  }\n",
    "  \n",
    "  return(df_cov_amount)\n",
    "}\n",
    "\n",
    "check_missing_positives <- function(df, rule_status=TRUE) {\n",
    "\n",
    "    df_merged <- inner_join(df, df_y, by = eid) %>% filter(status == 1)\n",
    "    diag_na <- summarize_na(df_merged, rule=rule_status)\n",
    "    print(diag_na)  \n",
    "}\n",
    "\n",
    "\n",
    "impute_continuous <- function(data) {\n",
    "  # Loop through all columns except 'eid'\n",
    "  for(col in setdiff(names(data), \"eid\")) {\n",
    "    # Check if the column is numeric (continuous)\n",
    "    if(is.numeric(data[[col]])) {\n",
    "      # Calculate median only if there are NA values to replace\n",
    "      if(any(is.na(data[[col]]))) {\n",
    "        med_val <- median(data[[col]], na.rm = TRUE)\n",
    "        data[[col]][is.na(data[[col]])] <- med_val\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  return(data)\n",
    "}\n",
    "\n",
    "impute_categorical <- function(data) {\n",
    "  # Function to calculate mode\n",
    "  get_mode <- function(x) {\n",
    "    ux <- unique(x)\n",
    "    ux[which.max(tabulate(match(x, ux)))]\n",
    "  }\n",
    "  \n",
    "  # Loop through all columns except 'eid'\n",
    "  for(col in setdiff(names(data), \"eid\")) {\n",
    "    # Check if the column is a factor or character (categorical)\n",
    "    if(is.factor(data[[col]]) || is.character(data[[col]])) {\n",
    "      # Calculate mode only if there are NA values to replace\n",
    "      if(any(is.na(data[[col]]))) {\n",
    "        mode_val <- get_mode(data[[col]][!is.na(data[[col]])])\n",
    "        data[[col]][is.na(data[[col]])] <- mode_val\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  return(data)\n",
    "}\n",
    "\n",
    "# Function to impute both continuous and categorical variables\n",
    "impute_all <- function(data) {\n",
    "  data <- impute_continuous(data)\n",
    "  data <- impute_categorical(data)\n",
    "  return(data)\n",
    "}\n",
    "\n",
    "\n",
    "minmax <- function(x, na.rm = TRUE) {\n",
    "  return((x- min(x, na.rm = na.rm)) /(max(x, na.rm = na.rm)-min(x, na.rm = na.rm)))\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "DOI <- \"HCC\"\n",
    "\n",
    "\n",
    "extract_year <- function(datetime_str) {\n",
    "  if (is.na(datetime_str)) {\n",
    "    return(NA)\n",
    "  }\n",
    "  \n",
    "  # Try parsing with lubridate\n",
    "  parsed_date <- ymd_hms(datetime_str, quiet = TRUE)\n",
    "  if (!is.na(parsed_date)) {\n",
    "    return(year(parsed_date))\n",
    "  }\n",
    "  \n",
    "  # If parsing fails, try extracting year with regex\n",
    "  year_match <- str_extract(datetime_str, \"\\\\d{4}\")\n",
    "  if (!is.na(year_match)) {\n",
    "    return(as.numeric(year_match))\n",
    "  }\n",
    "  \n",
    "  # If all else fails, return NA\n",
    "  return(NA)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date of primary consent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# Get date of primary consent\n",
    "# - https://support.researchallofus.org/hc/en-us/articles/13176125767188-How-to-find-participant-enrollment-data\n",
    "# - use to compute age from dob\n",
    "\n",
    "DATASET <- Sys.getenv('WORKSPACE_CDR')\n",
    "\n",
    "primary_consent_date_df <- bq_table_download(bq_project_query(\n",
    "    Sys.getenv(\"GOOGLE_PROJECT\"), page_size = 25000,\n",
    "    query = str_glue(\"\n",
    "-- Compute the count of unique participants in our All of Us cohort.\n",
    "SELECT DISTINCT\n",
    "    person_id,\n",
    "    MIN(observation_date) AS primary_consent_date\n",
    "FROM \n",
    "    `{DATASET}.concept`\n",
    "JOIN \n",
    "    `{DATASET}.concept_ancestor` \n",
    "        ON concept_id = ancestor_concept_id\n",
    "JOIN \n",
    "    `{DATASET}.observation` \n",
    "        ON descendant_concept_id = observation_source_concept_id\n",
    "WHERE \n",
    "    concept_name = 'Consent PII' AND concept_class_id = 'Module'\n",
    "GROUP BY 1\n",
    "\")))\n",
    "\n",
    "head(primary_consent_date_df)\n",
    "str(primary_consent_date_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ls()\n",
    "str(primary_consent_date_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dim(primary_consent_date_df)\n",
    "min(primary_consent_date_df$primary_consent_date)\n",
    "\n",
    "print(paste(\"NAs in 'Date of attending' Spalte: \", sum(is.na(primary_consent_date_df$`primary_consent_date`))))\n",
    "\n",
    "print(paste(\"Out of range from 2006-today: \", sum(primary_consent_date_df$`primary_consent_date` < as.Date(\"2006-01-01\") | \n",
    "    primary_consent_date_df$`primary_consent_date` > Sys.Date())))\n",
    "\n",
    "print(paste(\"Inconsistent format: \", sum(as.character(primary_consent_date_df$`primary_consent_date`, format = \"%Y-%m-%d\") != primary_consent_date_df$`primary_consent_date`)))\n",
    "\n",
    "df_covariates <- primary_consent_date_df\n",
    "\n",
    "write.table(df_covariates, \"Jan/HCC_covariates_1.1.txt\", sep=\"\\t\", quote=F, row.names=F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age and  Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"Jan_HCC_Covariates\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_03039562_person_sql <- paste(\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.gender_concept_id,\n",
    "        p_gender_concept.concept_name as gender,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        person.race_concept_id,\n",
    "        p_race_concept.concept_name as race,\n",
    "        person.ethnicity_concept_id,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        person.sex_at_birth_concept_id,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `person` person \n",
    "    LEFT JOIN\n",
    "        `concept` p_gender_concept \n",
    "            ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "person_03039562_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"person_03039562\",\n",
    "  \"person_03039562_*.csv\")\n",
    "message(str_glue('The data will be written to {person_03039562_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_03039562_person_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  person_03039562_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {person_03039562_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(gender = col_character(), race = col_character(), ethnicity = col_character(), sex_at_birth = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "#person_03039562_path <- \"gs://fc-secure-b96fb036-3379-4be0-8834-e7e486f2b76e/bq_exports/davidz1@researchallofus.org/20240509/person_03039562/person_03039562_*.csv\"\n",
    "person_03039562_path <- \"gs://fc-secure-7ce90512-cbaf-4591-985d-a48ed28a7fda/bq_exports/janclusmann@researchallofus.org/20240730/person_03039562/person_03039562_*.csv\"\n",
    "dataset_03039562_person_df <- read_bq_export_from_workspace_bucket(person_03039562_path)\n",
    "\n",
    "dim(dataset_03039562_person_df)\n",
    "\n",
    "head(dataset_03039562_person_df, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "unique(dataset_03039562_person_df$race)\n",
    "unique(dataset_03039562_person_df$ethnicity)\n",
    "race_counts <- table(dataset_03039562_person_df$race)\n",
    "\n",
    "# Get the proportions\n",
    "race_proportions <- prop.table(race_counts)\n",
    "\n",
    "# Combine counts and proportions into a data frame\n",
    "race_summary <- data.frame(\n",
    "  Count = race_counts,\n",
    "  Proportion = race_proportions\n",
    ")\n",
    "\n",
    "# Print the result\n",
    "print(race_summary)\n",
    "race_summary <- race_summary[order(-race_summary$Count.Var1),]\n",
    "pie(race_counts, main=\"Proportion of Races\")\n",
    "\n",
    "# Further preprocessing of race/ethnicity see \"Ethnicity Processing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_covariates <- data.table::fread(\"HCC/HCC_covariates_1.1.txt\", sep=\"\\t\")\n",
    "head(df_covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_covariates <- data.table::fread(\"HCC/HCC_covariates_1.1.txt\", sep=\"\\t\")\n",
    "dim(df_covariates)\n",
    "\n",
    "dataset_03039562_person_df <- dataset_03039562_person_df %>%\n",
    "    select(person_id, date_of_birth, sex_at_birth, race)\n",
    "\n",
    "df_covariates <- merge(df_covariates, dataset_03039562_person_df, by=\"person_id\")\n",
    "df_covariates$date_of_birth <- as.Date(df_covariates$date_of_birth)\n",
    "df_covariates$primary_consent_date <- as.Date(df_covariates$primary_consent_date)\n",
    "df_covariates$AGE <- as.numeric(difftime(df_covariates$primary_consent_date, df_covariates$date_of_birth, unit=\"days\"))/365.25\n",
    "\n",
    "df_covariates <- df_covariates %>%\n",
    "    select(-date_of_birth)\n",
    "\n",
    "# df_covariates$AGE_cat <- cut(df_covariates$AGE,\n",
    "#                         breaks = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, max(df_covariates$AGE)),\n",
    "#                         labels = c(\"0-10\", \"10-20\", \"20-30\", \"30-40\", \"40-50\", \"50-60\", \"60-70\", \"70-80\", \"80-90\", \">90\"))\n",
    "# table(df_covariates$AGE_cat, useNA = \"ifany\")\n",
    "\n",
    "df_covariates <- df_covariates %>%\n",
    "    rename(SEX = sex_at_birth) %>%\n",
    "    filter(SEX %in% c(\"Female\",\"Male\"))\n",
    "\n",
    "table(df_covariates$SEX)\n",
    "\n",
    "dim(df_covariates)\n",
    "head(df_covariates)\n",
    "\n",
    "#df_covariates$SEX <- factor(df_covariates$SEX, levels = c(0, 1), labels = c(\"Female\", \"Male\"))\n",
    "\n",
    "#levels(df_covariates$SEX)\n",
    "\n",
    "write.table(df_covariates, \"HCC/HCC_covariates_1.2.txt\", sep=\"\\t\", quote=F, row.names=F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BMI, Height, Weight, Waist, BP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"Jan_HCC_Covariates\" for domain \"measurement\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_35873912_measurement_sql <- paste(\"\n",
    "    SELECT\n",
    "        measurement.person_id,\n",
    "        measurement.measurement_concept_id,\n",
    "        m_standard_concept.concept_name as standard_concept_name,\n",
    "        m_standard_concept.concept_code as standard_concept_code,\n",
    "        m_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "        measurement.measurement_datetime,\n",
    "        measurement.measurement_type_concept_id,\n",
    "        m_type.concept_name as measurement_type_concept_name,\n",
    "        measurement.operator_concept_id,\n",
    "        m_operator.concept_name as operator_concept_name,\n",
    "        measurement.value_as_number,\n",
    "        measurement.value_as_concept_id,\n",
    "        m_value.concept_name as value_as_concept_name,\n",
    "        measurement.unit_concept_id,\n",
    "        m_unit.concept_name as unit_concept_name,\n",
    "        measurement.range_low,\n",
    "        measurement.range_high,\n",
    "        measurement.visit_occurrence_id,\n",
    "        m_visit.concept_name as visit_occurrence_concept_name,\n",
    "        measurement.measurement_source_value,\n",
    "        measurement.measurement_source_concept_id,\n",
    "        m_source_concept.concept_name as source_concept_name,\n",
    "        m_source_concept.concept_code as source_concept_code,\n",
    "        m_source_concept.vocabulary_id as source_vocabulary,\n",
    "        measurement.unit_source_value,\n",
    "        measurement.value_source_value \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `measurement` measurement \n",
    "        WHERE\n",
    "            (\n",
    "                measurement_source_concept_id IN (SELECT\n",
    "                    DISTINCT c.concept_id \n",
    "                FROM\n",
    "                    `cb_criteria` c \n",
    "                JOIN\n",
    "                    (SELECT\n",
    "                        CAST(cr.id as string) AS id       \n",
    "                    FROM\n",
    "                        `cb_criteria` cr       \n",
    "                    WHERE\n",
    "                        concept_id IN (903107, 903115, 903118, 903121, 903124, 903133, 903135)       \n",
    "                        AND full_text LIKE '%_rank1]%'      ) a \n",
    "                        ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                        OR c.path LIKE CONCAT('%.', a.id) \n",
    "                        OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                        OR c.path = a.id) \n",
    "                WHERE\n",
    "                    is_standard = 0 \n",
    "                    AND is_selectable = 1)\n",
    "            )) measurement \n",
    "    LEFT JOIN\n",
    "        `concept` m_standard_concept \n",
    "            ON measurement.measurement_concept_id = m_standard_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` m_type \n",
    "            ON measurement.measurement_type_concept_id = m_type.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` m_operator \n",
    "            ON measurement.operator_concept_id = m_operator.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` m_value \n",
    "            ON measurement.value_as_concept_id = m_value.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` m_unit \n",
    "            ON measurement.unit_concept_id = m_unit.concept_id \n",
    "    LEFT JOIn\n",
    "        `visit_occurrence` v \n",
    "            ON measurement.visit_occurrence_id = v.visit_occurrence_id \n",
    "    LEFT JOIN\n",
    "        `concept` m_visit \n",
    "            ON v.visit_concept_id = m_visit.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` m_source_concept \n",
    "            ON measurement.measurement_source_concept_id = m_source_concept.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "measurement_35873912_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"measurement_35873912\",\n",
    "  \"measurement_35873912_*.csv\")\n",
    "message(str_glue('The data will be written to {measurement_35873912_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_35873912_measurement_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  measurement_35873912_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {measurement_35873912_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(standard_concept_name = col_character(), standard_concept_code = col_character(), standard_vocabulary = col_character(), measurement_type_concept_name = col_character(), operator_concept_name = col_character(), value_as_concept_name = col_character(), unit_concept_name = col_character(), visit_occurrence_concept_name = col_character(), measurement_source_value = col_character(), source_concept_name = col_character(), source_concept_code = col_character(), source_vocabulary = col_character(), unit_source_value = col_character(), value_source_value = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "\n",
    "#measurement_35873912_path <- \"gs://fc-secure-b96fb036-3379-4be0-8834-e7e486f2b76e/bq_exports/davidz1@researchallofus.org/20240517/measurement_35873912/measurement_35873912_*.csv\"\n",
    "measurement_35873912_path <- \"gs://fc-secure-b96fb036-3379-4be0-8834-e7e486f2b76e/bq_exports/davidz1@researchallofus.org/20240517/measurement_35873912/measurement_35873912_*.csv\"\n",
    "\n",
    "dataset_35873912_measurement_df <- read_bq_export_from_workspace_bucket(measurement_35873912_path)\n",
    "\n",
    "dim(dataset_35873912_measurement_df)\n",
    "\n",
    "head(dataset_35873912_measurement_df, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_covariates <- data.table::fread(\"HCC/HCC_covariates_1.2.txt\", sep=\"\\t\")\n",
    "dim(df_covariates)\n",
    "\n",
    "measurement_df <- dataset_35873912_measurement_df %>%\n",
    "    select(person_id, standard_concept_name, value_as_number) %>%\n",
    "    filter(standard_concept_name != \"Computed blood pressure systolic and diastolic, mean of 2nd and 3rd measures\")\n",
    "\n",
    "measurement_df$standard_concept_name[measurement_df$standard_concept_name == \"Body height\"] <- \"Standing height\"\n",
    "measurement_df$standard_concept_name[measurement_df$standard_concept_name == \"Body mass index (BMI) [Ratio]\"] <- \"BMI\"\n",
    "measurement_df$standard_concept_name[measurement_df$standard_concept_name == \"Computed systolic blood pressure, mean of 2nd and 3rd measures\"] <- \"SBP\"\n",
    "measurement_df$standard_concept_name[measurement_df$standard_concept_name == \"Computed diastolic blood pressure, mean of 2nd and 3rd measures\"] <- \"DBP\"\n",
    "measurement_df$standard_concept_name[measurement_df$standard_concept_name == \"Computed waist circumference, mean of closest two measures\"] <- \"Waist circumference\"\n",
    "measurement_df$standard_concept_name[measurement_df$standard_concept_name == \"Body weight\"] <- \"Weight\"\n",
    "\n",
    "measurement_df <- pivot_wider(measurement_df, names_from = standard_concept_name, values_from = value_as_number)\n",
    "\n",
    "df_covariates <- merge(df_covariates, measurement_df, by=\"person_id\")\n",
    "\n",
    "dim(df_covariates)\n",
    "head(df_covariates)\n",
    "\n",
    "### Impute by calculation\n",
    "bmi_NA <- sum(is.na(df_covariates$BMI))\n",
    "print(paste(\"Number of NA values in BMI before imputation:\", bmi_NA))\n",
    "\n",
    "df_covariates$BMI[is.na(df_covariates$`BMI`) & !is.na(df_covariates$Weight) & !is.na(df_covariates$`Standing height`)] <- df_covariates$Weight[is.na(df_covariates$`BMI`) & !is.na(df_covariates$Weight) & !is.na(df_covariates$`Standing height`)] / (df_covariates$`Standing height`[is.na(df_covariates$`BMI`) & !is.na(df_covariates$Weight) & !is.na(df_covariates$`Standing height`)]/100)^2\n",
    "bmi_NA <- sum(is.na(df_covariates$BMI))\n",
    "print(paste(\"Number of NA values in BMI after manual calculation:\", bmi_NA))\n",
    "\n",
    "### Impute by waist circumference in categories\n",
    "df_covariates$BMI_cat <- cut(df_covariates$BMI,\n",
    "                        breaks = c(0, 18.5, 24.9, 29.9, max(df_covariates$BMI, na.rm=T)),\n",
    "                        labels = c(\"Underweight\", \"Normal weight\", \"Overweight\", \"Obese\"))\n",
    "bmi_NA <- sum(is.na(df_covariates$BMI) & !is.na(df_covariates$`Waist circumference`))\n",
    "print(paste(\"Number of NA values that could be imputed by estimation from Waist circumference:\", bmi_NA))\n",
    "\n",
    "### ********** CHANGED SEX *************** ###\n",
    "#Label as obese or normal according to WHO definition\n",
    "df_covariates$BMI_cat[is.na(df_covariates$BMI_cat) & (df_covariates$`Waist circumference` >= 80) & (df_covariates$SEX == \"Female\")] <- \"Obese\"\n",
    "df_covariates$BMI_cat[is.na(df_covariates$BMI_cat) & (df_covariates$`Waist circumference` < 80) & (df_covariates$SEX == \"Female\")] <- \"Normal weight\"\n",
    "df_covariates$BMI_cat[is.na(df_covariates$BMI_cat) & (df_covariates$`Waist circumference` >= 94) & (df_covariates$SEX == \"Male\")] <- \"Obese\"\n",
    "df_covariates$BMI_cat[is.na(df_covariates$BMI_cat) & (df_covariates$`Waist circumference` < 94) & (df_covariates$SEX == \"Male\")] <- \"Normal weight\"\n",
    "\n",
    "# Calculate mean for Group \"Normal weight\" and \"Obese\" according to waist circumference and Sex\n",
    "normal_men <- mean(df_covariates$BMI[df_covariates$BMI_cat == \"Normal weight\" & df_covariates$SEX==\"Male\"], na.rm=TRUE)\n",
    "normal_women <- mean(df_covariates$BMI[df_covariates$BMI_cat == \"Normal weight\" & df_covariates$SEX==\"Female\"], na.rm=TRUE)\n",
    "obese_men <- mean(df_covariates$BMI[df_covariates$BMI_cat == \"Obese\" & df_covariates$SEX==\"Male\"], na.rm=TRUE)\n",
    "obese_women <- mean(df_covariates$BMI[df_covariates$BMI_cat == \"Obese\" & df_covariates$SEX==\"Female\"], na.rm=TRUE)\n",
    "\n",
    "#Store mean of groups normal/obese for men/women (Not great but better than just mean imputing)\n",
    "df_covariates$BMI[is.na(df_covariates$BMI) & !is.na(df_covariates$`Waist circumference`) & df_covariates$SEX== \"Male\"] <- ifelse(df_covariates$BMI_cat[is.na(df_covariates$BMI) & !is.na(df_covariates$`Waist circumference`) & df_covariates$SEX== \"Male\"] == \"Normal weight\", normal_men, obese_men) \n",
    "df_covariates$BMI[is.na(df_covariates$BMI) & !is.na(df_covariates$`Waist circumference`) & df_covariates$SEX== \"Female\"] <- ifelse(df_covariates$BMI_cat[is.na(df_covariates$BMI) & !is.na(df_covariates$`Waist circumference`) & df_covariates$SEX== \"Female\"] == \"Normal weight\", normal_women, obese_women) \n",
    "\n",
    "bmi_NA <- sum(is.na(df_covariates$BMI))\n",
    "print(paste(\"Number of NA values after imputation from Waist circumference:\", bmi_NA))\n",
    "\n",
    "dim(df_covariates)\n",
    "head(df_covariates)\n",
    "\n",
    "#dim(df_covariates[complete.cases(df_covariates[,c(\"BMI\", \"Waist circumference\", \"Weight\", \"Standing height\")]), ])\n",
    "#df_covariates <- df_covariates[complete.cases(df_covariates[,c(\"BMI\", \"Waist circumference\", \"Weight\", \"Standing height\")]), ]\n",
    "\n",
    "write.table(df_covariates, \"HCC/HCC_covariates_1.3.txt\", sep=\"\\t\", quote=F, row.names=F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Smoking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"Jan_HCC_Smoking\" for domain \"survey\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_22980624_survey_sql <- paste(\"\n",
    "    SELECT\n",
    "        answer.person_id,\n",
    "        answer.survey_datetime,\n",
    "        answer.survey,\n",
    "        answer.question_concept_id,\n",
    "        answer.question,\n",
    "        answer.answer_concept_id,\n",
    "        answer.answer,\n",
    "        answer.survey_version_concept_id,\n",
    "        answer.survey_version_name  \n",
    "    FROM\n",
    "        `ds_survey` answer   \n",
    "    WHERE\n",
    "        (\n",
    "            question_concept_id IN (1585857, 1585860, 1585873, 1586159, 1586162)\n",
    "        )\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "survey_22980624_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"survey_22980624\",\n",
    "  \"survey_22980624_*.csv\")\n",
    "message(str_glue('The data will be written to {survey_22980624_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_22980624_survey_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  survey_22980624_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {survey_22980624_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(survey = col_character(), question = col_character(), answer = col_character(), survey_version_name = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "survey_22980624_path <- \"gs://fc-secure-b96fb036-3379-4be0-8834-e7e486f2b76e/bq_exports/davidz1@researchallofus.org/20240517/survey_22980624/survey_22980624_*.csv\"\n",
    "dataset_22980624_survey_df <- read_bq_export_from_workspace_bucket(survey_22980624_path)\n",
    "\n",
    "dim(dataset_22980624_survey_df)\n",
    "\n",
    "head(dataset_22980624_survey_df, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_covariates <- data.table::fread(\"Jan/HCC_covariates_1.3.txt\", sep=\"\\t\")\n",
    "head(df_covariates)\n",
    "\n",
    "survey_df <- dataset_22980624_survey_df %>%\n",
    "    select(person_id, question, answer)\n",
    "\n",
    "survey_df$question[survey_df$question == \"Smoking: 100 Cigs Lifetime\"] <- \"Ever smoked\"\n",
    "survey_df$question[survey_df$question == \"Smoking: Smoke Frequency\"] <- \"Smoking status\"\n",
    "survey_df$question[survey_df$question == \"Smoking: Average Daily Cigarette Number\"] <- \"Avg daily\"\n",
    "survey_df$question[survey_df$question == \"Smoking: Current Daily Cigarette Number\"] <- \"Current daily\"\n",
    "survey_df$question[survey_df$question == \"Smoking: Number Of Years\"] <- \"Years\"\n",
    "\n",
    "survey_df <- pivot_wider(survey_df, names_from = question, values_from = answer)\n",
    "\n",
    "df_covariates <- merge(df_covariates, survey_df, by=\"person_id\")\n",
    "\n",
    "# Change ever smoked to yes, no, NA (we don't know)\n",
    "df_covariates$`Ever smoked`[df_covariates$`Ever smoked` == \"100 Cigs Lifetime: Yes\"] <- \"Yes\"\n",
    "df_covariates$`Ever smoked`[df_covariates$`Ever smoked` == \"100 Cigs Lifetime: No\"] <- \"No\"\n",
    "df_covariates$`Ever smoked`[grepl(\"PMI\", df_covariates$`Ever smoked`)] <- NA\n",
    "\n",
    "# Change avg daily and years to NA if no answer (there's no way to impute)\n",
    "df_covariates$`Avg daily`[grepl(\"PMI\", df_covariates$`Avg daily`)] <- NA\n",
    "df_covariates$`Years`[grepl(\"PMI\", df_covariates$`Years`)] <- NA\n",
    "\n",
    "# Compute pack years\n",
    "df_covariates$`Pack years` <- NA\n",
    "df_covariates$`Pack years`[!is.na(df_covariates$`Avg daily`) & !is.na(df_covariates$`Years`)] <- (as.numeric(df_covariates$`Avg daily`[!is.na(df_covariates$`Avg daily`) & !is.na(df_covariates$`Years`)]) / 20) * \n",
    "                                                                                                           as.numeric(df_covariates$`Years`[!is.na(df_covariates$`Avg daily`) & !is.na(df_covariates$`Years`)])\n",
    "quantile(df_covariates$`Pack years`, na.rm=T)\n",
    "\n",
    "#Impute ever smoked (is NA - no way of knowing)\n",
    "df_covariates$`Ever smoked`[is.na(df_covariates$`Ever smoked`) & df_covariates$`Pack years` >= 0] <- \"Yes\"\n",
    "df_covariates$`Ever smoked`[is.na(df_covariates$`Ever smoked`) & df_covariates$`Smoking status` != \"Never\"] <- \"Yes\"\n",
    "df_covariates$`Ever smoked`[is.na(df_covariates$`Ever smoked`) & df_covariates$`Current daily` > 0] <- \"Yes\"\n",
    "#df_covariates$`Ever smoked`[is.na(df_covariates$`Ever smoked`)] <- \"No\"\n",
    "#table(df_covariates$`Ever smoked`, useNA = \"ifany\")\n",
    "\n",
    "# Impute smoking status\n",
    "df_covariates$`Smoking status`[df_covariates$`Smoking status` == \"Smoke Frequency: Every Day\"] <- \"Current\"\n",
    "df_covariates$`Smoking status`[df_covariates$`Smoking status` == \"Smoke Frequency: Some Days\"] <- \"Current\"\n",
    "df_covariates$`Smoking status`[df_covariates$`Smoking status` == \"Smoke Frequency: Not At All\"] <- \"Previous\"\n",
    "df_covariates$`Smoking status`[grepl(\"PMI\", df_covariates$`Smoking status`)] <- \"Previous\"\n",
    "df_covariates$`Smoking status`[df_covariates$`Ever smoked` == \"Yes\" & is.na(df_covariates$`Smoking status`)] <- \"Previous\"\n",
    "df_covariates$`Smoking status`[df_covariates$`Ever smoked` == \"No\" & is.na(df_covariates$`Smoking status`)] <- \"Never\"\n",
    "\n",
    "#Pack years = 0 imputed from Smoking status=never or Ever smoked=No\n",
    "df_covariates$`Pack years`[df_covariates$`Ever smoked` == \"No\" | df_covariates$`Smoking status` == \"Never\"] <- 0 \n",
    "\n",
    "#All others have smoking = yes and will get the mean Pack years\n",
    "print(paste0(\"Mean pack years: \", mean(df_covariates$`Pack years`, na.rm=T)))\n",
    "df_covariates$`Pack years`[is.na(df_covariates$`Pack years`) & !is.na(df_covariates$`Ever smoked`)] <- mean(df_covariates$`Pack years`, na.rm=T)\n",
    "quantile(df_covariates$`Pack years`, na.rm=T)\n",
    "\n",
    "#############################\n",
    "### Should missing smoking also get mean pack years? for now no - can add later or just remove pts\n",
    "#############################\n",
    "\n",
    "df_covariates <- df_covariates %>%\n",
    "    select(-`Avg daily`, -`Current daily`, -`Years`)\n",
    "\n",
    "sum(is.na(df_covariates$`Smoking status`))\n",
    "sum(is.na(df_covariates$`Ever smoked`))\n",
    "sum(is.na(df_covariates$`Pack years`))\n",
    "\n",
    "#set factors with labels/levels\n",
    "#df_covariates[\"Ever smoked\"] <- factor(df_covariates$`Ever smoked`, levels=c(0, 1), labels = c(\"No\", \"Yes\"))\n",
    "#df_covariates[\"Smoking status\"] <- factor(df_covariates$`Smoking status`, levels=c(0, 1, 2), labels = c(\"Never\", \"Previous\", \"Current\"))\n",
    "\n",
    "dim(df_covariates)\n",
    "head(df_covariates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "adjust_outliers <- function(df, column_name) {\n",
    "    # Ensure the column exists in the dataframe\n",
    "    if (!column_name %in% colnames(df)) {\n",
    "        stop(paste(\"Column\", column_name, \"does not exist in the dataframe\"))\n",
    "    }\n",
    "\n",
    "    # Calculate the 99th percentile\n",
    "    quantile_999 <- quantile(df[[column_name]], 0.999, na.rm = TRUE)\n",
    "\n",
    "    # Identify outliers\n",
    "    outliers <- df[[column_name]] > quantile_999\n",
    "    outliers_count <- sum(outliers, na.rm = TRUE)\n",
    "    outliers_range <- range(df[[column_name]][outliers], na.rm = TRUE)\n",
    "\n",
    "    # Replace outliers with the 99th percentile value\n",
    "    df[[column_name]] <- ifelse(outliers, quantile_999, df[[column_name]])\n",
    "\n",
    "    # Print the range of values that were cut\n",
    "    cat(\"Outliers detected and adjusted to the 99th percentile limit:\\n\")\n",
    "    cat(\"Number of outliers:\", outliers_count, \"\\n\")\n",
    "    cat(\"Range of outliers:\", outliers_range, \"\\n\")\n",
    "    cat(\"99.9th percentile limit:\", quantile_999, \"\\n\")\n",
    "\n",
    "    return(df)\n",
    "}\n",
    "\n",
    "df_covariates <- adjust_outliers(df_covariates, 'Pack years')\n",
    "\n",
    "quantile(df_covariates$`Pack years`, na.rm=T)\n",
    "\n",
    "dim(df_covariates)\n",
    "head(df_covariates)\n",
    "\n",
    "write.table(df_covariates, \"Jan/HCC_covariates_1.4.txt\", sep=\"\\t\", quote=F, row.names=F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "quantile(df_covariates$`Pack years`, na.rm=T)\n",
    "quantile(test$`Pack years`, na.rm=T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alcohol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"Jan_HCC_Alcohol\" for domain \"survey\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_05380700_survey_sql <- paste(\"\n",
    "    SELECT\n",
    "        answer.person_id,\n",
    "        answer.survey_datetime,\n",
    "        answer.survey,\n",
    "        answer.question_concept_id,\n",
    "        answer.question,\n",
    "        answer.answer_concept_id,\n",
    "        answer.answer,\n",
    "        answer.survey_version_concept_id,\n",
    "        answer.survey_version_name  \n",
    "    FROM\n",
    "        `ds_survey` answer   \n",
    "    WHERE\n",
    "        (\n",
    "            question_concept_id IN (1586198, 1586201, 1586207, 1586213)\n",
    "        )\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "survey_05380700_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"survey_05380700\",\n",
    "  \"survey_05380700_*.csv\")\n",
    "message(str_glue('The data will be written to {survey_05380700_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_05380700_survey_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  survey_05380700_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {survey_05380700_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(survey = col_character(), question = col_character(), answer = col_character(), survey_version_name = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "survey_05380700_path <- \"gs://fc-secure-b96fb036-3379-4be0-8834-e7e486f2b76e/bq_exports/davidz1@researchallofus.org/20240523/survey_05380700/survey_05380700_*.csv\"\n",
    "dataset_05380700_survey_df <- read_bq_export_from_workspace_bucket(survey_05380700_path)\n",
    "\n",
    "dim(dataset_05380700_survey_df)\n",
    "\n",
    "head(dataset_05380700_survey_df, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_covariates <- data.table::fread(\"Jan/HCC_covariates_1.4.txt\", sep=\"\\t\")\n",
    "head(df_covariates)\n",
    "\n",
    "survey_df <- dataset_05380700_survey_df %>%\n",
    "    select(person_id, question, answer)\n",
    "\n",
    "survey_df$question[survey_df$question == \"Alcohol: Alcohol Participant\"] <- \"Ever drank\"\n",
    "survey_df$question[survey_df$question == \"Alcohol: Drink Frequency Past Year\"] <- \"Past year\"\n",
    "survey_df$question[survey_df$question == \"Alcohol: Average Daily Drink Count\"] <- \"Avg daily\"\n",
    "survey_df$question[survey_df$question == \"Alcohol: 6 or More Drinks Occurrence\"] <- \"More six\"\n",
    "\n",
    "survey_df <- pivot_wider(survey_df, names_from = question, values_from = answer)\n",
    "\n",
    "df_covariates <- merge(df_covariates, survey_df, by=\"person_id\")\n",
    "\n",
    "# Rename `Past year`\n",
    "df_covariates$`Past year`[df_covariates$`Past year` == \"Drink Frequency Past Year: Never\"] <- 0\n",
    "df_covariates$`Past year`[df_covariates$`Past year` == \"Drink Frequency Past Year: Monthly Or Less\"] <- 1/4.345\n",
    "df_covariates$`Past year`[df_covariates$`Past year` == \"Drink Frequency Past Year: 2 to 4 Per Month\"] <- 3/4.345\n",
    "df_covariates$`Past year`[df_covariates$`Past year` == \"Drink Frequency Past Year: 2 to 3 Per Week\"] <- 2.5\n",
    "df_covariates$`Past year`[df_covariates$`Past year` == \"Drink Frequency Past Year: 4 or More Per Week\"] <- 4\n",
    "df_covariates$`Past year`[grepl(\"PMI\", df_covariates$`Past year`)] <- NA\n",
    "\n",
    "# Rename `Avg daily`\n",
    "df_covariates$`Avg daily`[df_covariates$`Avg daily` == \"Average Daily Drink Count: 1 or 2\"] <- 1.5\n",
    "df_covariates$`Avg daily`[df_covariates$`Avg daily` == \"Average Daily Drink Count: 3 or 4\"] <- 3.5\n",
    "df_covariates$`Avg daily`[df_covariates$`Avg daily` == \"Average Daily Drink Count: 5 or 6\"] <- 5.5\n",
    "df_covariates$`Avg daily`[df_covariates$`Avg daily` == \"Average Daily Drink Count: 7 to 9\"] <- 8\n",
    "df_covariates$`Avg daily`[df_covariates$`Avg daily` == \"Average Daily Drink Count: 10 or More\"] <- 10\n",
    "df_covariates$`Avg daily`[grepl(\"PMI\", df_covariates$`Avg daily`)] <- NA\n",
    "\n",
    "# Compute alk_g_d\n",
    "df_covariates$`Alk_g_d` <- NA\n",
    "df_covariates$`Alk_g_d`[!is.na(df_covariates$`Past year`) & !is.na(df_covariates$`Avg daily`)] <- \n",
    "    as.numeric(df_covariates$`Past year`[!is.na(df_covariates$`Past year`) & !is.na(df_covariates$`Avg daily`)]) * \n",
    "    as.numeric(df_covariates$`Avg daily`[!is.na(df_covariates$`Past year`) & !is.na(df_covariates$`Avg daily`)]) *\n",
    "    14 / 7\n",
    "df_covariates$`Alk_g_d`[df_covariates$`Ever drank` == \"Alcohol Participant: No\"] <- 0\n",
    "df_covariates$`Alk_g_d`[df_covariates$`Past year` == 0] <- 0\n",
    "# Otherwise keep NA if missing - if they prefer not to answer, we cannot make assumption\n",
    "\n",
    "df_covariates <- df_covariates %>%\n",
    "    select(-`Ever drank`, -`Past year`, -`Avg daily`, -`More six`)\n",
    "\n",
    "quantile(df_covariates$`Alk_g_d`, na.rm=T)\n",
    "\n",
    "dim(df_covariates)\n",
    "head(df_covariates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "adjust_outliers <- function(df, column_name) {\n",
    "    # Ensure the column exists in the dataframe\n",
    "    if (!column_name %in% colnames(df)) {\n",
    "        stop(paste(\"Column\", column_name, \"does not exist in the dataframe\"))\n",
    "    }\n",
    "\n",
    "    # Calculate the 99th percentile\n",
    "    quantile_999 <- quantile(df[[column_name]], 0.999, na.rm = TRUE)\n",
    "\n",
    "    # Identify outliers\n",
    "    outliers <- df[[column_name]] > quantile_999\n",
    "    outliers_count <- sum(outliers, na.rm = TRUE)\n",
    "    outliers_range <- range(df[[column_name]][outliers], na.rm = TRUE)\n",
    "\n",
    "    # Replace outliers with the 99th percentile value\n",
    "    df[[column_name]] <- ifelse(outliers, quantile_999, df[[column_name]])\n",
    "\n",
    "    # Print the range of values that were cut\n",
    "    cat(\"Outliers detected and adjusted to the 99th percentile limit:\\n\")\n",
    "    cat(\"Number of outliers:\", outliers_count, \"\\n\")\n",
    "    cat(\"Range of outliers:\", outliers_range, \"\\n\")\n",
    "    cat(\"99.9th percentile limit:\", quantile_999, \"\\n\")\n",
    "\n",
    "    return(df)\n",
    "}\n",
    "\n",
    "df_covariates <- adjust_outliers(df_covariates, 'Alk_g_d')\n",
    "\n",
    "# WHO's gender-specific limits\n",
    "df_covariates$Path_Alk <- ifelse(df_covariates$SEX == \"Male\", df_covariates$`Alk_g_d` / 60, df_covariates$`Alk_g_d` / 40)\n",
    "df_covariates$Path_Alk <- ifelse(df_covariates$Path_Alk >= 1, 1, ifelse(df_covariates$Path_Alk < 0.9999999999, 0, df_covariates$Path_Alk))\n",
    "df_covariates$High_Alk <- ifelse(df_covariates$SEX == \"Male\", df_covariates$`Alk_g_d` / 24, df_covariates$`Alk_g_d` / 12)\n",
    "df_covariates$High_Alk <- ifelse(df_covariates$High_Alk >= 1, 1, ifelse(df_covariates$High_Alk < 0.9999999999, 0, df_covariates$High_Alk))\n",
    "\n",
    "dim(df_covariates)\n",
    "head(df_covariates)\n",
    "\n",
    "write.table(df_covariates, \"Jan/HCC_covariates_1.5.txt\", sep=\"\\t\", quote=F, row.names=F)\n",
    "\n",
    "sum(!is.na(df_covariates$`Alk_g_d`) & df_covariates$`Alk_g_d` > 0)\n",
    "quantile(df_covariates$`Alk_g_d`, na.rm=T)\n",
    "mean(df_covariates$`Alk_g_d`, na.rm=T)\n",
    "sd(df_covariates$`Alk_g_d`, na.rm=T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Deprivation index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"Jan_HCC_Deprivation\" for domain \"zip_code_socioeconomic\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_14505310_zip_code_socioeconomic_sql <- paste(\"\n",
    "    SELECT\n",
    "        observation.person_id,\n",
    "        observation.observation_datetime,\n",
    "        zip_code.zip3_as_string as zip_code,\n",
    "        zip_code.fraction_assisted_income as assisted_income,\n",
    "        zip_code.fraction_high_school_edu as high_school_education,\n",
    "        zip_code.median_income,\n",
    "        zip_code.fraction_no_health_ins as no_health_insurance,\n",
    "        zip_code.fraction_poverty as poverty,\n",
    "        zip_code.fraction_vacant_housing as vacant_housing,\n",
    "        zip_code.deprivation_index,\n",
    "        zip_code.acs as american_community_survey_year \n",
    "    FROM\n",
    "        `zip3_ses_map` zip_code \n",
    "    JOIN\n",
    "        `observation` observation \n",
    "            ON CAST(SUBSTR(observation.value_as_string, 0, STRPOS(observation.value_as_string, '*') - 1) AS INT64) = zip_code.zip3 \n",
    "            AND observation_source_concept_id = 1585250 \n",
    "            AND observation.value_as_string NOT LIKE 'Res%'\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "zip_code_socioeconomic_14505310_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"zip_code_socioeconomic_14505310\",\n",
    "  \"zip_code_socioeconomic_14505310_*.csv\")\n",
    "message(str_glue('The data will be written to {zip_code_socioeconomic_14505310_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_14505310_zip_code_socioeconomic_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  zip_code_socioeconomic_14505310_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {zip_code_socioeconomic_14505310_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(zip3_as_string = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "zip_code_socioeconomic_14505310_path <- \"gs://fc-secure-b96fb036-3379-4be0-8834-e7e486f2b76e/bq_exports/davidz1@researchallofus.org/20240522/zip_code_socioeconomic_14505310/zip_code_socioeconomic_14505310_*.csv\"\n",
    "dataset_14505310_zip_code_socioeconomic_df <- read_bq_export_from_workspace_bucket(zip_code_socioeconomic_14505310_path)\n",
    "\n",
    "dim(dataset_14505310_zip_code_socioeconomic_df)\n",
    "\n",
    "head(dataset_14505310_zip_code_socioeconomic_df, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_covariates <- data.table::fread(\"Jan/HCC_covariates_1.5.txt\", sep=\"\\t\")\n",
    "head(df_covariates)\n",
    "\n",
    "dep_idx <- dataset_14505310_zip_code_socioeconomic_df %>%\n",
    "    select(person_id, deprivation_index)\n",
    "\n",
    "df_covariates <- merge(df_covariates, dep_idx, by=\"person_id\")\n",
    "\n",
    "dim(df_covariates)\n",
    "head(df_covariates)\n",
    "\n",
    "write.table(df_covariates, \"Jan/HCC_covariates_1.6.txt\", sep=\"\\t\", quote=F, row.names=F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"Jan_HCC_Medications\" for domain \"survey\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_00748392_survey_sql <- paste(\"\n",
    "    SELECT\n",
    "        answer.person_id,\n",
    "        answer.survey_datetime,\n",
    "        answer.survey,\n",
    "        answer.question_concept_id,\n",
    "        answer.question,\n",
    "        answer.answer_concept_id,\n",
    "        answer.answer,\n",
    "        answer.survey_version_concept_id,\n",
    "        answer.survey_version_name  \n",
    "    FROM\n",
    "        `ds_survey` answer   \n",
    "    WHERE\n",
    "        (\n",
    "            question_concept_id IN (1384437, 1384641, 43528793, 43528819, 43528820, 836799, 836800)\n",
    "        )\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "survey_00748392_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"survey_00748392\",\n",
    "  \"survey_00748392_*.csv\")\n",
    "message(str_glue('The data will be written to {survey_00748392_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_00748392_survey_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  survey_00748392_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {survey_00748392_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(survey = col_character(), question = col_character(), answer = col_character(), survey_version_name = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "survey_00748392_path <- \"gs://fc-secure-b96fb036-3379-4be0-8834-e7e486f2b76e/bq_exports/davidz1@researchallofus.org/20240523/survey_00748392/survey_00748392_*.csv\"\n",
    "dataset_00748392_survey_df <- read_bq_export_from_workspace_bucket(survey_00748392_path)\n",
    "\n",
    "dim(dataset_00748392_survey_df)\n",
    "\n",
    "head(dataset_00748392_survey_df, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_covariates <- data.table::fread(\"Jan/HCC_covariates_1.6.txt\", sep=\"\\t\")\n",
    "head(df_covariates)\n",
    "\n",
    "survey_df <- dataset_00748392_survey_df %>%\n",
    "    select(person_id, question, answer)\n",
    "\n",
    "survey_df$question[survey_df$question == \"Are you currently prescribed medications and/or receiving treatment for high blood pressure (hypertension)?\"] <- \"HTN\"\n",
    "survey_df$question[survey_df$question == \"Are you currently prescribed medications and/or receiving treatment for high cholesterol?\"] <- \"High Chol\"\n",
    "survey_df$question[survey_df$question == \"Are you currently prescribed medications and/or receiving treatment for other hormone/endocrine condition(s)?\"] <- \"Hormone\"\n",
    "survey_df$question[survey_df$question == \"Are you currently prescribed medications and/or receiving treatment for type 1 diabetes?\"] <- \"T1DM\"\n",
    "survey_df$question[survey_df$question == \"Are you currently prescribed medications and/or receiving treatment for type 2 diabetes?\"] <- \"T2DM\"\n",
    "survey_df$question[survey_df$question == \"Including yourself, who in your family has had type 1 diabetes? Select all that apply.\"] <- \"T1DM Fam\"\n",
    "survey_df$question[survey_df$question == \"Including yourself, who in your family has had type 2 diabetes? Select all that apply.\"] <- \"T2DM Fam\"\n",
    "\n",
    "# Set NA responses to 0 as well\n",
    "htn_ids <- survey_df$person_id[survey_df$question == \"HTN\" & survey_df$answer == \"Are you currently prescribed medications and/or receiving treatment for high blood pressure (hypertension)? - Yes\"]\n",
    "chol_ids <- survey_df$person_id[survey_df$question == \"High Chol\" & survey_df$answer == \"Are you currently prescribed medications and/or receiving treatment for high cholesterol? - Yes\"]\n",
    "t1dm_ids <- survey_df$person_id[survey_df$question == \"T1DM\" & survey_df$answer == \"Are you currently prescribed medications and/or receiving treatment for type 1 diabetes? - Yes\"]\n",
    "t2dm_ids <- survey_df$person_id[survey_df$question == \"T2DM\" & survey_df$answer == \"Are you currently prescribed medications and/or receiving treatment for type 2 diabetes? - Yes\"]\n",
    "metabolic_ids <- unique(c(htn_ids, chol_ids, t1dm_ids, t2dm_ids))\n",
    "hormone_ids <- survey_df$person_id[survey_df$question == \"Hormone\" & survey_df$answer == \"Are you currently prescribed medications and/or receiving treatment for other hormone/endocrine condition(s)? - Yes\"]\n",
    "\n",
    "df_covariates$Medication <- 0\n",
    "df_covariates$Medication[df_covariates$person_id %in% metabolic_ids] <- 1\n",
    "df_covariates$Medication[df_covariates$person_id %in% hormone_ids] <- 2\n",
    "df_covariates$Medication <- factor(df_covariates$Medication, levels=c(0,1,2), labels= c(\"No Medication\", \"Metabolic\", \"Hormones\"))\n",
    "\n",
    "table(df_covariates$Medication)\n",
    "\n",
    "# Family diabetes\n",
    "t1dm_ids <- survey_df$person_id[survey_df$question == \"T1DM Fam\" &\n",
    "                                (survey_df$answer == \"Including yourself, who in your family has had type 1 diabetes? - Father\" | \n",
    "                                 survey_df$answer == \"Including yourself, who in your family has had type 1 diabetes? - Mother\" |\n",
    "                                 survey_df$answer == \"Including yourself, who in your family has had type 1 diabetes? - Sibling\")]\n",
    "t2dm_ids <- survey_df$person_id[survey_df$question == \"T2DM Fam\" &\n",
    "                                (survey_df$answer == \"Including yourself, who in your family has had type 2 diabetes? - Father\" | \n",
    "                                 survey_df$answer == \"Including yourself, who in your family has had type 2 diabetes? - Mother\" |\n",
    "                                 survey_df$answer == \"Including yourself, who in your family has had type 2 diabetes? - Sibling\")]\n",
    "dm_ids <- unique(c(t1dm_ids, t2dm_ids))\n",
    "\n",
    "df_covariates$Family_diabetes <- 0\n",
    "df_covariates$Family_diabetes[df_covariates$person_id %in% dm_ids] <- 1\n",
    "df_covariates$Family_diabetes <- as.factor(df_covariates$Family_diabetes)\n",
    "\n",
    "table(df_covariates$Family_diabetes)\n",
    "\n",
    "dim(df_covariates)\n",
    "head(df_covariates)\n",
    "\n",
    "write.table(df_covariates, \"Jan/HCC_covariates_1.7.txt\", sep=\"\\t\", quote=F, row.names=F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_covariates <- data.table::fread(\"HCC/HCC_covariates_1.7.txt\", sep=\"\\t\")\n",
    "df_covariates <- df_covariates %>% select(-(c(\"AGE_cat\")))\n",
    "\n",
    "\n",
    "\n",
    "#write.table(df_covariates, \"HCC/HCC_covariates_1.7.txt\", sep=\"\\t\", quote=F, row.names=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICD codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process ICD codes for covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "icd_codes_subset <- data.table::fread(\"HCC/HCC_ICD_codes_subset.txt\", sep=\"\\t\")\n",
    "\n",
    "dim(icd_codes_subset)\n",
    "head(icd_codes_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "icd_codes_subset$source_concept_code <- gsub(\"\\\\.\", \"\", icd_codes_subset$source_concept_code)\n",
    "icd_codes_subset$source_concept_code <- substr(icd_codes_subset$source_concept_code, 1, 4)\n",
    "\n",
    "head(icd_codes_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ICD Groups\n",
    "ICD_Groups <- data.table::fread(\"Jan/ICD_Groups.txt\", sep=\"\\t\")\n",
    "\n",
    "pat_icds_labelled <- left_join(x = ICD_Groups, y = icd_codes_subset %>% select(person_id, source_concept_code) %>% distinct(), \n",
    "                               by = c(\"ICD10\" = \"source_concept_code\")) %>% \n",
    "                     distinct()\n",
    "\n",
    "dim(pat_icds_labelled)\n",
    "#head(pat_icds_labelled)\n",
    "\n",
    "#Check for amount of diagnosis per actual ICD, instead of group. Likely here will be the correct amounts, while summarized will be less due to parallel coded diagnosis\n",
    "df_icd_groups_before <- pat_icds_labelled %>% group_by(Diagnosis, person_id) %>% summarise(occurence = n()) %>% spread(Diagnosis, occurence) \n",
    "sum_groups_before <- as.data.frame(colSums(df_icd_groups_before, na.rm=TRUE))\n",
    "\n",
    "head(sum_groups_before)\n",
    "\n",
    "#Groupby + summarises\n",
    "df_icd_groups <- pat_icds_labelled %>% group_by(Group, person_id) %>% summarise(occurence = n()) %>% spread(Group, occurence) \n",
    "df_icd_groups[df_icd_groups > 1 & df_icd_groups < 100]<- 1 \n",
    "df_icd_groups[is.na(df_icd_groups)] <- 0\n",
    "sum_groups_after <- as.data.frame(colSums(df_icd_groups))\n",
    "\n",
    "head(sum_groups_before)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ICD Singles\n",
    "ICD_Singles <- data.table::fread(\"Jan/ICD_Singles.txt\", sep=\"\\t\")\n",
    "\n",
    "pat_icds_labelled <- left_join(x = ICD_Singles, y = icd_codes_subset %>% select(person_id, source_concept_code) %>% distinct(), \n",
    "                               by = c(\"ICD10\" = \"source_concept_code\"))%>% \n",
    "                     distinct() \n",
    "\n",
    "dim(pat_icds_labelled)\n",
    "\n",
    "#Groupby + summarises\n",
    "df_icd_singles <- pat_icds_labelled %>% group_by(Diagnosis, person_id) %>% summarise(occurence = n()) %>% spread(Diagnosis, occurence) \n",
    "df_icd_singles[df_icd_singles > 1 & df_icd_singles < 10000]<- 1 \n",
    "df_icd_singles[is.na(df_icd_singles)] <- 0\n",
    "sum_singles <- as.data.frame(colSums(df_icd_singles))\n",
    "\n",
    "head(sum_singles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# DM ICD codes\n",
    "icd_dm_codes <- data.table::fread(\"Jan/HCC_ICD_codes_DM.txt\", sep=\"\\t\")\n",
    "\n",
    "icd_dm <- icd_dm_codes %>%\n",
    "    select(person_id) %>%\n",
    "    distinct()\n",
    "icd_dm$DM <- 1\n",
    "icd_dm <- select(icd_dm, c(person_id, DM))\n",
    "\n",
    "dim(icd_dm)\n",
    "head(icd_dm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Merging groups and singles\n",
    "df_icd <- full_join(df_icd_singles, df_icd_groups, by = \"person_id\")\n",
    "df_icd <- merge(df_icd, icd_dm, by=\"person_id\", all=TRUE)\n",
    "df_icd <- replace(df_icd, is.na(df_icd), 0)\n",
    "\n",
    "dim(df_icd)\n",
    "head(df_icd)\n",
    "\n",
    "### Note:\n",
    "### - person_id '0' represents all codes that had NO patients diagnosed\n",
    "\n",
    "\n",
    "### Include 'control' patients - patients with no diagnoses\n",
    "icd_person_ids <- read.table(\"data/AllofUs_v7_phenotype_icd_091223_person_ids.txt\", sep=\"\\t\", header=T)\n",
    "\n",
    "df_icd <- merge(df_icd, icd_person_ids, by=\"person_id\", all=TRUE)\n",
    "df_icd[is.na(df_icd)] <- 0\n",
    "\n",
    "dim(df_icd)\n",
    "head(df_icd)\n",
    "\n",
    "write.table(df_icd, \"Jan/HCC_df_diagnosis.txt\", sep=\"\\t\", quote=F, row.names=F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Summarize ICD codes\n",
    "create_summary <- function(df) {\n",
    "  total_rows <- nrow(df)\n",
    "  summary_df <- df %>% \n",
    "    summarise(across(-person_id, ~sum(. == \"1\", na.rm = TRUE))) %>% \n",
    "    pivot_longer(everything(), names_to = \"Diagnosis\", values_to = \"Occurrence\") %>% \n",
    "    mutate(Percentage = (Occurrence / total_rows) * 100) %>%\n",
    "    arrange(desc(Occurrence))\n",
    "  \n",
    "  as.data.frame(summary_df)\n",
    "}\n",
    "\n",
    "df_icd <- data.table::fread(\"HCC/HCC_df_diagnosis.txt\", sep=\"\\t\")\n",
    "\n",
    "sum_diagnosis <- create_summary(df_icd)\n",
    "sum_diagnosis\n",
    "sum_diagnosis_sorted <- sum_diagnosis[order(sum_diagnosis$Diagnosis), ]\n",
    "sum_diagnosis_sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract HCC cases/controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "icd_codes_subset <- data.table::fread(\"HCC/HCC_ICD_codes_subset.txt\", sep=\"\\t\")\n",
    "\n",
    "dim(icd_codes_subset)\n",
    "head(icd_codes_subset)\n",
    "\n",
    "icd_codes_subset$source_concept_code <- gsub(\"\\\\.\", \"\", icd_codes_subset$source_concept_code)\n",
    "icd_codes_subset$source_concept_code <- substr(icd_codes_subset$source_concept_code, 1, 4)\n",
    "\n",
    "head(icd_codes_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process HCC cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "HCC_cases <- icd_codes_subset[icd_codes_subset$source_concept_code == \"C220\",]\n",
    "HCC_cases <- HCC_cases %>%\n",
    "  mutate(condition_start_datetime = ymd_hms(condition_start_datetime))\n",
    "\n",
    "# Filter for the first visit per unique person_id\n",
    "HCC_cases_first_visit <- HCC_cases %>%\n",
    "  group_by(person_id) %>%\n",
    "  arrange(condition_start_datetime) %>%\n",
    "  slice(1) %>%\n",
    "  ungroup() %>%\n",
    "  mutate(year = sapply(condition_start_datetime, extract_year))\n",
    "\n",
    "# Check the result\n",
    "print(paste(\"Original number of rows:\", nrow(HCC_cases)))\n",
    "print(paste(\"Number of rows after filtering:\", nrow(HCC_cases_first_visit)))\n",
    "print(paste(\"Number of unique person_ids:\", n_distinct(HCC_cases_first_visit$person_id)))\n",
    "\n",
    "# Optional: View the first few rows of the result\n",
    "\n",
    "df_nan <- read_xlsx(\"HCC/df_nan.xlsx\")\n",
    "df_y <- data.table::fread(\"HCC/HCC_case_controls.txt\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Inner_join on patients with all necessary data\n",
    "HCC_cases_final <- HCC_cases_first_visit %>%\n",
    "  inner_join(df_y[df_y$status == 1, ], by = \"person_id\")\n",
    "nrow(HCC_cases_final)\n",
    "head(HCC_cases_final)\n",
    "\n",
    "# Create a dataframe of cases that were removed (here due to missing information)\n",
    "df_discard <- df_y %>%\n",
    "  filter(status == 1) %>%\n",
    "  anti_join(df_nan, by = \"person_id\") %>%\n",
    "  select(person_id)\n",
    "print(paste(\"Number of discarded cases:\", nrow(df_discard)))\n",
    "\n",
    "\n",
    "HCC_cases_final <- HCC_cases_final %>%\n",
    "  mutate(discard = ifelse(person_id %in% df_discard$person_id, 1, 0))\n",
    "\n",
    "# Print summary of the new 'discard' column\n",
    "print(table(HCC_cases_final$discard))\n",
    "\n",
    "# Optional: View the first few rows of the updated HCC_cases_final\n",
    "head(HCC_cases_final)\n",
    "\n",
    "\n",
    "doi_included <- nrow(HCC_cases_final) - nrow(df_discard)\n",
    "doi_discarded <- nrow(df_discard)\n",
    "doi_included\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot HCC Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if (!requireNamespace(\"systemfonts\", quietly = TRUE)) install.packages(\"systemfonts\")\n",
    "if (!requireNamespace(\"showtext\", quietly = TRUE)) install.packages(\"showtext\")\n",
    "library(systemfonts)\n",
    "library(showtext)\n",
    "\n",
    "n_total <- nrow(df_y) #Assess absolute number\n",
    "\n",
    "plot_included_discarded_cases <- function(df, base_size = 18, n_total) {\n",
    "    if (systemfonts::system_fonts() %>% filter(family == \"Arial\") %>% nrow() > 0) {\n",
    "    font_family <- \"Arial\"\n",
    "  } else {\n",
    "    font_family <- \"Open Sans\"\n",
    "    font_add_google(\"Open Sans\", \"Open Sans\")\n",
    "  }\n",
    "  \n",
    "  showtext_auto()\n",
    "  doi_included <- get(\"doi_included\", envir = .GlobalEnv)\n",
    "  doi_discarded <- get(\"doi_discarded\", envir = .GlobalEnv)\n",
    "  included_label <- paste(\"Included (n=\", doi_included, \")\", sep = \"\") # Custom labels for the legend\n",
    "  discarded_label <- paste(\"Discarded (n=\", doi_discarded, \")\", sep = \"\")\n",
    "\n",
    "  plot <- ggplot(df, aes(x = year, fill = as.factor(discard))) +\n",
    "    geom_histogram(binwidth = 1, color = \"black\", size=0.2, width= 0.5) +\n",
    "    scale_fill_manual(values = c(\"grey\", \"#808080\"), \n",
    "                      labels = c(included_label, discarded_label), \n",
    "                      name = \"\") + \n",
    "    \n",
    "    xlab(\"Year\") +\n",
    "    ylab(\"Absolute number of cases\") +\n",
    "    ggtitle(paste(\"Year of\", DOI, \"Diagnosis\")) +\n",
    "    theme_minimal(base_family = font_family) +\n",
    "    theme(text = element_text(family = font_family),\n",
    "          plot.title = element_text(hjust = 0.5, size = base_size), # Increase size to 150% \n",
    "          legend.position = c(0.3, 0.9), # upper left corner\n",
    "          axis.title.x = element_text(size = base_size), \n",
    "          axis.title.y = element_text(size = base_size),\n",
    "          axis.title.y.right = element_text(size = base_size, angle=90, vjust=-0.5),\n",
    "          axis.text.y.right = element_text(size = base_size, colour = \"black\"),\n",
    "          legend.text = element_text(size = base_size), \n",
    "          axis.text.x = element_text(size = base_size, colour=\"black\", vjust=0.1), \n",
    "          axis.text.y = element_text(size = base_size, colour=\"black\"),\n",
    "          panel.grid.major = element_blank(), # Remove major grid lines\n",
    "          panel.grid.minor = element_blank(), # Remove minor grid lines\n",
    "          plot.margin = margin(0.5, 0.5, 0.5, 0.5, \"cm\"),\n",
    "          panel.border = element_rect(colour = \"black\", fill = NA, linewidth = 1.5),\n",
    "          legend.spacing.y = unit(2, \"cm\"),\n",
    "          legend.key = element_rect(colour = \"white\", fill = NA)) +\n",
    "  scale_y_continuous(\n",
    "      expand = c(0, 0), \n",
    "      limits = c(0, NA),\n",
    "      sec.axis = sec_axis(\n",
    "        ~. / n_total * 100000,\n",
    "        name = \"Incidence [n / 100.000]\"\n",
    "      )\n",
    "    )\n",
    "  guides(fill = guide_legend(override.aes = list(colour = \"white\")))\n",
    "  \n",
    "  print(plot)\n",
    "  ggsave(filename = \"HCC/HCC_yearly_cases.svg\", plot = plot, width = 10, height = 10, bg = \"transparent\")\n",
    "  \n",
    "  }\n",
    "\n",
    "plot_included_discarded_cases(HCC_cases_final, base_size=30, n_total = n_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore diseases underlying HCC cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank priority of diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### Function to plot stacked bar charts\n",
    "\n",
    "\n",
    "stacked_bars_time_comparison <- function(df, base_size=18) {\n",
    "  priority_order <- c(\"Cirrhosis\", \"Viral Hepatitis\", \"CLD\", \"No Liver disease\")\n",
    "  \n",
    "  df <- df %>%\n",
    "    mutate(Priority = priority(Group)) %>%\n",
    "    arrange(Time, Priority) %>%\n",
    "    group_by(Time) %>%\n",
    "    mutate(LabelPos = cumsum(Count) - 0.5 * Count) %>% # Calculate label positions on cumulative sum column for label positioning\n",
    "    ungroup() %>%\n",
    "    mutate(Group = factor(Group, levels = priority_order))\n",
    "  print(head(df))\n",
    "  \n",
    "  max_x_value <- max(as.numeric(as.factor(df$Time))) + 1\n",
    "  df$max_x <- max_x_value  # add max_x to the dataframe\n",
    "  \n",
    "  label_data <- df %>%\n",
    "    filter(Order == 2) %>%\n",
    "    distinct(Group, .keep_all = TRUE)\n",
    "  \n",
    "  plot <- ggplot(data = df, aes(x = Time, y = Count, fill = Group)) +\n",
    "    geom_bar(stat = \"identity\", position = position_stack(vjust = 0.5, reverse = TRUE), width=0.55 ) +\n",
    "    geom_text(aes(label = Count, y = LabelPos), size = base_size * 0.4, colour = \"black\", vjust = -0.3) +\n",
    "    geom_text(aes(label = sprintf(\"%.0f%%\", Percentage), y = LabelPos), size = base_size * 0.3, colour = \"black\", vjust = 1.2) +\n",
    "    geom_text(data = distinct(label_data, Group, .keep_all = TRUE), \n",
    "              aes(x = max_x - 0.4, label = Group, y = LabelPos), hjust=0, size = base_size * 0.4, color = \"black\") +\n",
    "    theme_minimal() +\n",
    "    labs(title = \"Etiology Over Time\",\n",
    "         y = \"Count\") +\n",
    "    scale_fill_brewer(palette = \"Set3\") +\n",
    "    theme(plot.title = element_text(size=base_size, hjust = 0.5),\n",
    "          axis.title.x =element_blank(),\n",
    "          axis.title.y = element_blank(),\n",
    "          legend.title = element_blank(),\n",
    "          legend.position = \"none\",\n",
    "          axis.text.x = element_text(size = base_size, colour = \"black\"),\n",
    "          axis.text.y = element_blank(),\n",
    "          panel.grid.major = element_blank(), # Remove major grid lines\n",
    "          panel.grid.minor = element_blank(), # Remove minor grid lines\n",
    "          plot.margin = margin(1, 300, 1, 10)) +\n",
    "    coord_cartesian(clip = 'off')\n",
    "\n",
    "  print(plot)\n",
    "  #print(df)\n",
    "  ggsave(filename = paste0(DOI, \"/HCC_etiology_over_time.svg\")), \n",
    "         plot = plot, width = 8, height = 10, bg = \"transparent\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "priority_order <- c(\"Cirrhosis\", \"Viral Hepatitis\", \"CLD\", \"No Liver disease\")\n",
    "\n",
    "pat_cld <- pat_icds[pat_icds$diag_icd10 %in% par_icd_codes | pat_icds$diag_icd9 %in% par_icd_codes, ] %>%\n",
    "  select(c(\"eid\", \"diag_icd9\", \"diag_icd10\", \"epistart\")) %>%\n",
    "  left_join(Patients_at_risk, by = c(\"diag_icd10\" = \"ICD10\")) %>%\n",
    "  right_join(df_y, by = \"eid\") %>%\n",
    "  subset(status==1) %>%\n",
    "  select(-c(\"location_name\", \"location_code\", \"location_nr\", \"location_country\", \"country_code\", \"split_ext\", \"split_int\"))\n",
    "\n",
    "pat_cld$epistart[is.na(pat_cld$Group)] <- as.Date(pat_cld$date_of_diag)\n",
    "\n",
    "pat_cld$Group[is.na(pat_cld$Group)] <- \"No Liver disease\"\n",
    "pat_cld$Group[!pat_cld$Group %in% par_subset] <- \"No Liver disease\" #Replace all non-matching groups with \"No LD\"\n",
    "pat_cld$Group <- factor(pat_cld$Group, levels=priority_order)\n",
    "\n",
    "summary(pat_cld$Group)\n",
    "\n",
    "priority <- function(diagnosis) {\n",
    "  case_when(\n",
    "    diagnosis == \"Cirrhosis\" ~ 1,\n",
    "    diagnosis == \"Viral Hepatitis\" ~ 2,\n",
    "    diagnosis == \"CLD\" ~ 3,\n",
    "    diagnosis == \"No Liver disease\" ~ 4,\n",
    "    TRUE ~ 5  # Assign a lower priority to other diagnoses\n",
    "  )\n",
    "}\n",
    "\n",
    "\n",
    "pat_cld <- pat_cld %>%\n",
    "  group_by(eid)\n",
    "\n",
    "# Node 0 represents first visit to hospital after assessment\n",
    "pat_cld_node0 <- pat_cld %>%\n",
    "  mutate(Priority = priority(Group)) %>%\n",
    "  group_by(eid) %>%\n",
    "  filter(epistart == min(epistart)) %>%\n",
    "  arrange(eid, Priority) %>%\n",
    "  filter(row_number() == 1) %>%\n",
    "  ungroup() %>%\n",
    "  select(-Priority)\n",
    "\n",
    "summary_node0 <- pat_cld_node0 %>%\n",
    "  group_by(Group) %>%\n",
    "  summarize(Count = n(), .groups = 'drop') %>%\n",
    "  mutate(Time = \"First \\nEHR\") %>%\n",
    "  mutate(Order = 1 ) %>%\n",
    "  mutate(Priority = priority(Group)) %>%\n",
    "  arrange(Priority) %>%\n",
    "  mutate(Percentage = round(Count / sum(Count) * 100)) \n",
    "\n",
    "\n",
    "\n",
    "pat_cld_node1 <- pat_cld %>%\n",
    "  mutate(Priority = priority(Group)) %>%\n",
    "  group_by(eid) %>%\n",
    "  #filter(epistart == max(epistart)) %>%   #better to take all incidents than just the last, as not all diags get coded everytime\n",
    "  arrange(eid, Priority) %>%\n",
    "  filter(row_number() == 1) %>%\n",
    "  ungroup() %>%\n",
    "  select(-Priority)\n",
    "\n",
    "summary_node1 <- pat_cld_node1 %>%\n",
    "  group_by(Group) %>%\n",
    "  summarize(Count = n(), .groups = 'drop') %>%\n",
    "  mutate(Time = paste0(\"Prior to\\n\", DOI)) %>%\n",
    "  mutate(Order = 2 ) %>%\n",
    "  mutate(Priority = priority(Group)) %>%\n",
    "  arrange(Priority) %>%\n",
    "  mutate(Percentage = round(Count / sum(Count) * 100))\n",
    "\n",
    "\n",
    "# View the summaries\n",
    "print(summary_node0)\n",
    "print(summary_node1)\n",
    "\n",
    "\n",
    "# Merge timepoints\n",
    "combined_data <- rbind(summary_node0, summary_node1)\n",
    "\n",
    "\n",
    "stacked_bars_time_comparison(combined_data, base_size=22)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Cirrhosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "check_unique_participants <- function(df, name) {\n",
    "  total_rows <- nrow(df)\n",
    "  unique_participants <- n_distinct(df$person_id)\n",
    "  print(paste(\"Checking\", name))\n",
    "  print(paste(\"Total rows:\", total_rows))\n",
    "  print(paste(\"Unique participants:\", unique_participants))\n",
    "}\n",
    "\n",
    "\n",
    "# Check cirrhosis_cases and HCC_cases\n",
    "check_unique_participants(cirrhosis_cases, \"Cirrhosis Cases\")\n",
    "check_unique_participants(HCC_cases, \"HCC Cases\")\n",
    "\n",
    "\n",
    "process_icd_codes <- function(icd_codes_subset, codes, disease_name, select_visits = \"first\") {\n",
    "  # Filter for the specified ICD codes\n",
    "  cases <- icd_codes_subset[icd_codes_subset$source_concept_code %in% codes, ]\n",
    "  \n",
    "  # Convert condition_start_datetime to datetime format\n",
    "  cases <- cases %>%\n",
    "    mutate(condition_start_datetime = ymd_hms(condition_start_datetime))\n",
    "  \n",
    "  # Function to extract year from datetime\n",
    "  extract_year <- function(date) {\n",
    "    return(year(date))\n",
    "  }\n",
    "  \n",
    "  # Process based on select_visits option\n",
    "  if (select_visits == \"first\") {\n",
    "    # Filter for the first visit per unique person_id\n",
    "    processed_cases <- cases %>%\n",
    "      group_by(person_id) %>%\n",
    "      arrange(condition_start_datetime) %>%\n",
    "      slice(1) %>%\n",
    "      ungroup()\n",
    "  } else if (select_visits == \"all\") {\n",
    "    # Keep all visits\n",
    "    processed_cases <- cases\n",
    "  } else {\n",
    "    stop(\"Invalid select_visits option. Use 'first' or 'all'.\")\n",
    "  }\n",
    "  \n",
    "  # Add year and date_of_diag columns\n",
    "  processed_cases <- processed_cases %>%\n",
    "    mutate(\n",
    "      year = sapply(condition_start_datetime, extract_year),\n",
    "      date_of_diag = as.Date(condition_start_datetime)\n",
    "    )\n",
    "  \n",
    "  # Add disease name column\n",
    "  processed_cases$disease <- disease_name\n",
    "  \n",
    "  # Print summary information\n",
    "  print(paste(\"Processing\", disease_name, \"cases:\"))\n",
    "  print(paste(\"ICD codes used:\", paste(codes, collapse = \", \")))\n",
    "  print(paste(\"Original number of rows:\", nrow(cases)))\n",
    "  print(paste(\"Number of rows after processing:\", nrow(processed_cases)))\n",
    "  print(paste(\"Number of unique person_ids:\", n_distinct(processed_cases$person_id)))\n",
    "  \n",
    "  # Optional: Count of cases per ICD code\n",
    "  if (length(codes) > 1) {\n",
    "    code_counts <- processed_cases %>%\n",
    "      group_by(source_concept_code) %>%\n",
    "      summarise(count = n()) %>%\n",
    "      arrange(desc(count))\n",
    "    print(\"Cases per ICD code:\")\n",
    "    print(code_counts)\n",
    "  }\n",
    "    \n",
    "  processed_cases <- processed_cases %>% select(c(\"person_id\", \"source_concept_code\", \"date_of_diag\", \"disease\"))\n",
    "  return(processed_cases)\n",
    "}\n",
    "\n",
    "cirrhosis_codes <- c(\"K703\", \"K743\", \"K745\", \"K746\", \"K767\", \"I850\", \"I859\", \"R18\")\n",
    "\n",
    "\n",
    "cirrhosis_cases <- process_icd_codes(icd_codes_subset, cirrhosis_codes, \"Cirrhosis\", \"first\")\n",
    "\n",
    "HCC_cases <- process_icd_codes(icd_codes_subset, \"C220\", \"HCC\", \"first\")\n",
    "\n",
    "\n",
    "check_unique_participants(cirrhosis_cases, \"Cirrhosis Cases\")\n",
    "check_unique_participants(HCC_cases, \"HCC Cases\")\n",
    "\n",
    "\n",
    "head(cirrhosis_cases)\n",
    "head(HCC_cases)\n",
    "dim(cirrhosis_cases)\n",
    "dim(HCC_cases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "time_threshold = 90\n",
    "print(time_threshold)\n",
    "\n",
    "cirrhosis_cases <- cirrhosis_cases %>%\n",
    "    mutate(date_of_diag = as.Date(date_of_diag))\n",
    "  \n",
    "HCC_cases <- HCC_cases %>%\n",
    "    mutate(date_of_diag = as.Date(date_of_diag))\n",
    "\n",
    "early_cirrhosis_cases <- merge(cirrhosis_cases, HCC_cases, by=\"person_id\", suffix = c(\"_cirrhosis\", \"_HCC\"), all=TRUE)\n",
    "\n",
    "sum(is.na(early_cirrhosis_cases$date_of_diag_HCC))\n",
    "\n",
    "early_cirrhosis_cases <- early_cirrhosis_cases %>%\n",
    "  mutate(\n",
    "    time_to_hcc = case_when(\n",
    "      !is.na(date_of_diag_HCC) & !is.na(date_of_diag_cirrhosis) ~ \n",
    "        as.numeric(difftime(date_of_diag_HCC, date_of_diag_cirrhosis, units = \"days\")),\n",
    "      TRUE ~ NA_real_\n",
    "    ),\n",
    "    cirrhosis_status = case_when(\n",
    "      is.na(date_of_diag_cirrhosis) & is.na(date_of_diag_HCC) ~ \"Neither Cirrhosis nor HCC\",\n",
    "      is.na(date_of_diag_HCC) ~ \"Cirrhosis but No HCC\",\n",
    "      is.na(date_of_diag_cirrhosis) ~ \"HCC but No Cirrhosis\",\n",
    "      time_to_hcc > time_threshold ~ \"Cirrhosis prior to HCC\",\n",
    "      time_to_hcc >= -time_threshold & time_to_hcc <= time_threshold ~ \"Simultaneous Cirrhosis + HCC\",\n",
    "      time_to_hcc < -time_threshold ~ \"Cirrhosis after HCC\",\n",
    "      TRUE ~ \"Error in date calculation\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "\n",
    "early_cirrhosis_cases\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "case_analysis <- early_cirrhosis_cases %>%\n",
    "    group_by(cirrhosis_status) %>%\n",
    "    summarize(count = n()) %>%\n",
    "    mutate(percentage = count / sum(count) * 100)\n",
    "  \n",
    "  print(\"Cirrhosis cases analysis:\")\n",
    "  print(case_analysis)\n",
    "\n",
    "early_cirrhosis_only <- early_cirrhosis_cases %>%\n",
    "  filter(cirrhosis_status %in% c(\"Cirrhosis but No HCC\", \"Cirrhosis prior to HCC\"))\n",
    "\n",
    "df_early_cirrhosis <- early_cirrhosis_only %>%\n",
    "  select(person_id) %>%\n",
    "  mutate(cirrhosis = 1) %>%\n",
    "  distinct()  \n",
    "\n",
    "write_csv(df_early_cirrhosis, \"HCC/df_early_cirrhosis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "early_cirrhosis_only\n",
    "\n",
    "df_cirrhosis <- early_cirrhosis_only %>% select(\"person_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# This code will apply the merge() function to each pair of data frames in the list list(df_eid, df_covariates, df_diagnosis, df_blood, df_snp), merging them based on the \"eid\" column.\n",
    "\n",
    "today <- format(Sys.Date(), \"%d_%m_%Y\")\n",
    "\n",
    "# Define overarching function\n",
    "merge_dataframes <- function(include_metabolomics = FALSE, filter_par = FALSE, normalize = FALSE) {\n",
    "    \n",
    "    convert_id_to_integer <- function(df) { # Function to ensure person_id is an integer\n",
    "        df$eid <- as.integer(df$eid)\n",
    "        return(df)\n",
    "    }\n",
    "    \n",
    "    # Initial list of dataframes to merge\n",
    "    dfs_to_merge <- list(df_covariates, df_diagnosis, df_blood)\n",
    "    \n",
    "    dfs_to_merge <- lapply(dfs_to_merge, convert_id_to_integer) # Convert 'eid' in each dataframe to integer\n",
    "\n",
    "    if (include_metabolomics) { # Conditionally add df_metabolomics and/or else\n",
    "        dfs_to_merge <- c(dfs_to_merge, list(df_metabolomics))\n",
    "    }\n",
    "    \n",
    "    df_merged <- Reduce(function(x, y) merge(x, y, by = \"eid\", all = FALSE), dfs_to_merge)  # Merging the dataframes\n",
    "    df_merged <- map_and_align(df_merged, \"HCC/columnmapper_ukb_aou.xlsx\")    \n",
    "    # Conditionally apply normalization function\n",
    "    if (normalize==TRUE) {\n",
    "        df_merged <- normalize_data(df_merged)\n",
    "        if (!is.integer(df_merged$eid)) {\n",
    "            stop(\"Error: 'eid' column is no longer an integer after normalization.\")\n",
    "        }\n",
    "    }\n",
    "    #df_merged <- df_merged %>% select(-all_of(diag_codes)) # Removing the column of interest\n",
    "          \n",
    "    # Filter the \"population at risk (par) by a prespecified if required\n",
    "    if (filter_par) {\n",
    "        df_merged <- filter_rows_with_pos_entries(df_merged)\n",
    "    }\n",
    "    #df_merged <- df_merged %>% select(-all_of(vec_blood_risk))\n",
    "        \n",
    "    # Determine the group status\n",
    "    if (include_metabolomics) {\n",
    "        col_subset <<- \"met\"\n",
    "    } else {\n",
    "        col_subset <<- \"basic\"\n",
    "    }\n",
    "    if (filter_par) {\n",
    "        row_subset <<- \"par\"\n",
    "    } else {\n",
    "        row_subset <<- \"all\"\n",
    "    }\n",
    "        \n",
    "    #if (normalize) {\n",
    "    #    assign(\"raw\", \"\", envir = .GlobalEnv)\n",
    "    #} else {\n",
    "    #    assign(\"raw\", \"_raw\", envir = .GlobalEnv)\n",
    "    #}\n",
    "\n",
    "    # Remove NAs and return the dataframe\n",
    "    #return(na.omit(df_merged))\n",
    "    return(df_merged)\n",
    "}\n",
    "\n",
    "                        \n",
    "summarize_continuous_columns <- function(df, columns_to_drop = c(), digits = 4) {\n",
    "  # Remove specified columns\n",
    "  df <- df %>% select(-any_of(columns_to_drop))\n",
    "  \n",
    "  # Select only numeric columns\n",
    "  numeric_columns <- df %>% select_if(is.numeric) %>% names()\n",
    "  \n",
    "  # Calculate summary statistics for numeric columns\n",
    "  summary_df <- df %>%\n",
    "    select(all_of(numeric_columns)) %>%\n",
    "    summarise(across(everything(), list(\n",
    "      mean = ~mean(., na.rm = TRUE),\n",
    "      median = ~median(., na.rm = TRUE),\n",
    "      max = ~max(., na.rm = TRUE),\n",
    "      min = ~min(., na.rm = TRUE)\n",
    "    )))\n",
    "  \n",
    "  # Reshape the dataframe\n",
    "  summary_df <- summary_df %>%\n",
    "    pivot_longer(cols = everything(),\n",
    "                 names_to = c(\"column\", \".value\"),\n",
    "                 names_pattern = \"(.*)_(mean|median|max|min)\")\n",
    "  \n",
    "  # Reorder columns\n",
    "  summary_df <- summary_df %>%\n",
    "    select(column, mean, median, max, min)\n",
    "  \n",
    "  # Format numbers to avoid scientific notation\n",
    "  summary_df <- summary_df %>%\n",
    "    mutate(across(c(mean, median, max, min), \n",
    "                  ~format(round(., digits), nsmall = digits, scientific = FALSE)))\n",
    "  \n",
    "  return(summary_df)\n",
    "}\n",
    "\n",
    "# Set options to display full numbers in console output\n",
    "options(scipen = 999)                     \n",
    "\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "# Convert units from AOU standard to UKB standard according to formula in conversion table                        \n",
    "convert_units <- function(df, conversion_table) {\n",
    "  # Create a copy of the dataframe to avoid modifying the original\n",
    "  df_converted <- df\n",
    "\n",
    "  # Iterate through each row in the conversion table\n",
    "  for (i in 1:nrow(conversion_table)) {\n",
    "    column <- conversion_table$column[i]\n",
    "    formula <- conversion_table$adjust_unit[i]\n",
    "    \n",
    "    if (column %in% names(df_converted)) {\n",
    "      if (formula != \"x\") {\n",
    "        tryCatch({\n",
    "          # Create a function from the formula string\n",
    "          convert_func <- if (column == \"HbA1c\") {\n",
    "            function(x) {\n",
    "              # Set a lower bound for plausible HbA1c values (3%)\n",
    "              x_cleaned <- pmax(x, 3)\n",
    "              # Apply conversion\n",
    "              (x_cleaned - 2.15) * 10.929\n",
    "            }\n",
    "          } else {\n",
    "            function(x) eval(parse(text = formula))\n",
    "          }\n",
    "          \n",
    "          # Store original values for reporting\n",
    "          original_values <- df_converted[[column]]\n",
    "          \n",
    "          # Apply the conversion\n",
    "          df_converted[[column]] <- sapply(df_converted[[column]], convert_func)\n",
    "          \n",
    "          # Print conversion information\n",
    "          cat(sprintf(\"Column '%s' converted: %s\\n\", column, \n",
    "              if(column == \"HbA1c\") \"(x - 2.15) * 10.929\" else formula))\n",
    "          cat(sprintf(\"  Original range: %f to %f\\n\", min(original_values, na.rm = TRUE), max(original_values, na.rm = TRUE)))\n",
    "          cat(sprintf(\"  Converted range: %f to %f\\n\", min(df_converted[[column]], na.rm = TRUE), max(df_converted[[column]], na.rm = TRUE)))\n",
    "          cat(sprintf(\"  Units changed from %s to %s\\n\", \n",
    "                      conversion_table$Unit_aou[i], \n",
    "                      conversion_table$Unit_ukb[i]))\n",
    "        }, error = function(e) {\n",
    "          cat(sprintf(\"Error converting column '%s': %s\\n\", column, e$message))\n",
    "        })\n",
    "      } else {\n",
    "        cat(sprintf(\"Column '%s' not converted (no conversion needed)\\n\", column))\n",
    "      }\n",
    "    } else {\n",
    "      cat(sprintf(\"Column '%s' not found in dataframe\\n\", column))\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(df_converted)\n",
    "}\n",
    "                        \n",
    "limit_df <- function(df, mapper) {\n",
    "  report <- list()\n",
    "  \n",
    "  for (i in 1:nrow(mapper)) {\n",
    "    col_name <- mapper$column[i]\n",
    "    upper <- mapper$upper_limit[i]\n",
    "    lower <- mapper$lower_limit[i]\n",
    "    \n",
    "    if (col_name %in% names(df)) {\n",
    "      original <- df[[col_name]]\n",
    "      modified <- original  # Start with a copy of the original\n",
    "      \n",
    "      # Only apply limits to non-NA values\n",
    "      non_na <- !is.na(original)\n",
    "      \n",
    "      if (!is.na(upper)) {\n",
    "        modified[non_na] <- pmin(modified[non_na], upper, na.rm = TRUE)\n",
    "      }\n",
    "      if (!is.na(lower)) {\n",
    "        modified[non_na] <- pmax(modified[non_na], lower, na.rm = TRUE)\n",
    "      }\n",
    "      \n",
    "      # Count changes (excluding NA values)\n",
    "      changes <- sum(original != modified & non_na, na.rm = TRUE)\n",
    "      upper_changes <- sum(original > upper & non_na, na.rm = TRUE)\n",
    "      lower_changes <- sum(original < lower & non_na, na.rm = TRUE)\n",
    "      \n",
    "      # Update the dataframe\n",
    "      df[[col_name]] <- modified\n",
    "      \n",
    "      report[[col_name]] <- list(\n",
    "        upper_limit = upper,\n",
    "        lower_limit = lower,\n",
    "        rows_exceeding_upper = upper_changes,\n",
    "        rows_below_lower = lower_changes,\n",
    "        total_modified_rows = changes,\n",
    "        total_na_values = sum(is.na(original))\n",
    "      )\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Print report\n",
    "  cat(\"Limit Application Report:\\n\")\n",
    "  cat(\"-------------------------\\n\")\n",
    "  for (col in names(report)) {\n",
    "    cat(sprintf(\"Column: %s\\n\", col))\n",
    "    cat(sprintf(\"  Upper limit: %s\\n\", report[[col]]$upper_limit))\n",
    "    cat(sprintf(\"  Lower limit: %s\\n\", report[[col]]$lower_limit))\n",
    "    cat(sprintf(\"  Rows exceeding upper limit: %d\\n\", report[[col]]$rows_exceeding_upper))\n",
    "    cat(sprintf(\"  Rows below lower limit: %d\\n\", report[[col]]$rows_below_lower))\n",
    "    cat(sprintf(\"  Total modified rows: %d\\n\", report[[col]]$total_modified_rows))\n",
    "    cat(sprintf(\"  Total NA values (unmodified): %d\\n\", report[[col]]$total_na_values))\n",
    "    cat(\"\\n\")\n",
    "  }\n",
    "  \n",
    "  return(list(df = df, report = report))\n",
    "}\n",
    "              \n",
    "              \n",
    "              \n",
    "              \n",
    "              \n",
    "adjust_outliers <- function(df, column_names = NULL) {\n",
    "  # Convert to data.table if it's not already\n",
    "  if (!is.data.table(df)) {\n",
    "    df <- as.data.table(df)\n",
    "  }\n",
    "  \n",
    "  # If column_names is not provided, use all numeric columns except 'eid'\n",
    "  if (is.null(column_names)) {\n",
    "    column_names <- setdiff(names(df)[sapply(df, is.numeric)], \"eid\")\n",
    "  } else {\n",
    "    # Ensure column_names is a character vector\n",
    "    column_names <- as.character(column_names)\n",
    "    \n",
    "    # Ensure all specified columns exist in the dataframe\n",
    "    missing_columns <- setdiff(column_names, colnames(df))\n",
    "    if (length(missing_columns) > 0) {\n",
    "      stop(paste(\"The following columns do not exist in the dataframe:\", \n",
    "                 paste(missing_columns, collapse = \", \")))\n",
    "    }\n",
    "    \n",
    "    # Ensure all specified columns are numeric\n",
    "    non_numeric_columns <- column_names[!sapply(df[, ..column_names], is.numeric)]\n",
    "    if (length(non_numeric_columns) > 0) {\n",
    "      stop(paste(\"The following columns are not numeric:\", \n",
    "                 paste(non_numeric_columns, collapse = \", \")))\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Sort column names alphabetically\n",
    "  column_names <- sort(column_names)\n",
    "  \n",
    "  # Remove 'eid' from the sorted list if it's present\n",
    "  column_names <- setdiff(column_names, \"eid\")\n",
    "  \n",
    "  cat(\"Columns will be processed in the following order:\\n\")\n",
    "  cat(paste(column_names, collapse = \", \"), \"\\n\\n\")\n",
    "  \n",
    "  for (column_name in column_names) {\n",
    "    # Calculate the 99.9th percentile\n",
    "    quantile_999 <- quantile(df[[column_name]], 0.999, na.rm = TRUE)\n",
    "    \n",
    "    # Identify outliers\n",
    "    outliers <- df[[column_name]] > quantile_999\n",
    "    outliers_count <- sum(outliers, na.rm = TRUE)\n",
    "    outliers_range <- range(df[[column_name]][outliers], na.rm = TRUE)\n",
    "    \n",
    "    # Replace outliers with the 99.9th percentile value\n",
    "    df[, (column_name) := fifelse(get(column_name) > quantile_999, quantile_999, get(column_name))]\n",
    "    \n",
    "    # Print the range of values that were cut\n",
    "    cat(\"\\nColumn:\", column_name, \"\\n\")\n",
    "    cat(\"Outliers detected and adjusted to the 99.9th percentile limit:\\n\")\n",
    "    cat(\"Number of outliers:\", outliers_count, \"\\n\")\n",
    "    cat(\"Range of outliers:\", paste(outliers_range, collapse = \" to \"), \"\\n\")\n",
    "    cat(\"99.9th percentile limit:\", quantile_999, \"\\n\")\n",
    "  }\n",
    "  \n",
    "  return(df)\n",
    "}\n",
    "\n",
    "\n",
    "              \n",
    "              \n",
    "adjust_outlier_to_ukb <- function(df, conversion_table) {\n",
    "  # Ensure the required columns exist in the conversion table\n",
    "  required_cols <- c(\"column\", \"max_ukb\")\n",
    "  if (!all(required_cols %in% colnames(conversion_table))) {\n",
    "    stop(\"Conversion table must contain 'column' and 'max_ukb' columns\")\n",
    "  }\n",
    "  \n",
    "  # Remove 'eid' from the conversion table if present\n",
    "  conversion_table <- conversion_table[conversion_table$column != \"eid\", ]\n",
    "  \n",
    "  # Create a named vector of max_ukb values, converting to numeric\n",
    "  max_ukb_values <- sapply(setNames(conversion_table$max_ukb, conversion_table$column), \n",
    "                           function(x) as.numeric(as.character(x)))\n",
    "  \n",
    "  # Iterate through each column in the conversion table\n",
    "  for (col in conversion_table$column) {\n",
    "    if (col %in% colnames(df) && col != \"eid\") {  # Explicit check to exclude 'eid'\n",
    "      # Get the current max value\n",
    "      current_max <- max(df[[col]], na.rm = TRUE)\n",
    "      \n",
    "      # Get the UKB max value\n",
    "      ukb_max <- max_ukb_values[col]\n",
    "      \n",
    "      # Check if ukb_max is NA (conversion to numeric failed)\n",
    "      if (is.na(ukb_max)) {\n",
    "        warning(sprintf(\"Unable to convert max_ukb value for column '%s' to numeric. Skipping this column.\", col))\n",
    "        next\n",
    "      }\n",
    "      \n",
    "      # Adjust values if current max is greater than UKB max\n",
    "      if (current_max > ukb_max) {\n",
    "        df[[col]] <- pmin(df[[col]], ukb_max)\n",
    "        cat(sprintf(\"Column '%s' adjusted: max value changed from %s to %s\\n\", \n",
    "                    col, format(current_max, scientific = FALSE), format(ukb_max, scientific = FALSE)))\n",
    "      } else {\n",
    "        cat(sprintf(\"Column '%s' not adjusted: current max (%s) is not greater than UKB max (%s)\\n\", \n",
    "                    col, format(current_max, scientific = FALSE), format(ukb_max, scientific = FALSE)))\n",
    "      }\n",
    "    } else if (col == \"eid\") {\n",
    "      cat(\"Column 'eid' skipped as per requirement.\\n\")\n",
    "    } else {\n",
    "      warning(sprintf(\"Column '%s' not found in the dataframe\", col))\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(df)\n",
    "}\n",
    "                           \n",
    "                           map_and_align <- function(df, mapper_path) {\n",
    "  # Read the mapper Excel file\n",
    "  mapper_df <- read_excel(mapper_path)\n",
    "  \n",
    "  # Create a named vector for renaming, excluding NA mappings\n",
    "  rename_vector <- setNames(mapper_df$column_ukb, mapper_df$column_aou)\n",
    "  rename_vector <- rename_vector[!is.na(rename_vector) & !is.na(names(rename_vector))]\n",
    "  \n",
    "  # Identify columns to remove (those with NA in column_ukb or column_aou)\n",
    "  columns_to_remove <- unique(c(\n",
    "    mapper_df$column_aou[is.na(mapper_df$column_ukb)],\n",
    "    mapper_df$column_aou[is.na(mapper_df$column_aou)]\n",
    "  ))\n",
    "  columns_to_remove <- columns_to_remove[!is.na(columns_to_remove)]  # Remove NA values\n",
    "  \n",
    "  # Rename columns\n",
    "  df_renamed <- df %>%\n",
    "    rename_with(~ ifelse(.x %in% names(rename_vector), rename_vector[.x], .x), everything())\n",
    "  \n",
    "  # Remove columns with NA mappings\n",
    "  df_final <- df_renamed %>%\n",
    "    select(-any_of(intersect(columns_to_remove, names(df_renamed))))\n",
    "  \n",
    "  # Identify columns that weren't renamed (no mapping found)\n",
    "  unmapped_cols <- setdiff(names(df_final), mapper_df$column_ukb[!is.na(mapper_df$column_ukb)])\n",
    "  \n",
    "  # Print summary\n",
    "  cat(\"Summary of map_and_align:\\n\")\n",
    "  cat(sprintf(\"- %d columns renamed\\n\", sum(names(df) %in% names(rename_vector))))\n",
    "  cat(sprintf(\"- %d columns identified for removal due to NA mapping\\n\", length(columns_to_remove)))\n",
    "  cat(sprintf(\"- %d columns actually removed\\n\", ncol(df_renamed) - ncol(df_final)))\n",
    "  cat(sprintf(\"- %d columns left unmapped\\n\", length(unmapped_cols)))\n",
    "  \n",
    "  # Print removed columns\n",
    "  if (length(columns_to_remove) > 0) {\n",
    "    cat(\"\\nColumns identified for removal due to NA mapping:\\n\")\n",
    "    print(columns_to_remove)\n",
    "  }\n",
    "  \n",
    "  # Print unmapped columns\n",
    "  if (length(unmapped_cols) > 0) {\n",
    "    cat(\"\\nColumns not renamed (no mapping found):\\n\")\n",
    "    print(unmapped_cols)\n",
    "  }\n",
    "  \n",
    "  return(df_final)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelim dfs for NA removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "omit.NA <- function(df, threshold) {\n",
    "  # Get initial number of rows\n",
    "  initial_rows <- nrow(df)\n",
    "  \n",
    "  # Find number of NA values per row\n",
    "  na_counts <- rowSums(is.na(df))\n",
    "  df <- df[na_counts <= threshold, ]\n",
    "  \n",
    "  # Calculate number of rows removed\n",
    "  rows_removed <- initial_rows - nrow(df)\n",
    "  \n",
    "  # Print information about removed rows\n",
    "  cat(sprintf(\"Rows removed: %d (%.2f%%)\\n\", \n",
    "              rows_removed, \n",
    "              (rows_removed / initial_rows) * 100))\n",
    "  cat(sprintf(\"Rows remaining: %d\\n\", nrow(df)))\n",
    "  \n",
    "  return(df)\n",
    "}\n",
    "\n",
    "analyze_na_thresholds <- function(df, max_threshold = 30, step = 5) {\n",
    "  results <- data.frame(\n",
    "    NA_Threshold = numeric(),\n",
    "    Total_Rows = numeric(),\n",
    "    Positive_Cases = numeric(),\n",
    "    stringsAsFactors = FALSE\n",
    "  )\n",
    "  \n",
    "  for (threshold in seq(0, max_threshold, by = step)) {\n",
    "    df_cleaned <- omit.NA(df, threshold)\n",
    "    \n",
    "    results <- rbind(results, data.frame(\n",
    "      NA_Threshold = threshold,\n",
    "      Total_Rows = nrow(df_cleaned),\n",
    "      Positive_Cases = sum(df_cleaned$status, na.rm = TRUE)\n",
    "    ))\n",
    "  }\n",
    "  \n",
    "  return(results)\n",
    "}\n",
    "\n",
    "df_y <- data.table::fread(\"HCC/HCC_case_controls.txt\", sep=\"\\t\")\n",
    "df_covariates <- data.table::fread(\"HCC/HCC_covariates_1.7.txt\", sep=\"\\t\")\n",
    "df_diagnosis <- data.table::fread(\"HCC/HCC_df_diagnosis.txt\", sep=\"\\t\")\n",
    "df_blood <- data.table::fread(\"HCC/HCC_df_blood.txt\", sep=\"\\t\")\n",
    "\n",
    "#df_x_temp <- merge_dataframes(filter_par = FALSE)\n",
    "\n",
    "dfs_to_merge <- list(df_covariates, df_diagnosis, df_blood, df_y)\n",
    "df_x_temp <- Reduce(function(x, y) merge(x, y, by = \"person_id\", all = FALSE), dfs_to_merge)\n",
    "all_na <- summarize_na(df_x_temp)\n",
    "print(all_na)\n",
    "write_xlsx(all_na, 'HCC/all_na.xlsx')\n",
    "\n",
    "\n",
    "df_x_temp2 <- omit.NA(df_x_temp, 25)\n",
    "#str(df_all_cleaned)\n",
    "df_nan <- df_x_temp2 %>% select(\"person_id\") #df containing all rows with less than X NaN per row, used for subsetting later\n",
    "write_xlsx(df_nan, \"HCC/df_nan.xlsx\")\n",
    "summarize_na(df_x_temp2)\n",
    "print(paste(\"Positive cases before removal of rows with >X NAs:\", sum(df_x_temp$status)))\n",
    "print(paste(\"Positive cases after removal of rows with >X NAs:\", sum(df_x_temp2$status)))\n",
    "                    \n",
    "print(paste(\"Total rows before removal of rows with >X NAs:\", nrow(df_x_temp)))\n",
    "print(paste(\"Total rows after removal of rows with >X NAs:\", nrow(df_x_temp2)))\n",
    "                    \n",
    "na_analysis <- analyze_na_thresholds(df_x_temp, max_threshold = 30, step = 5)\n",
    "print(na_analysis)\n",
    "\n",
    "# Optionally, you can write this to an Excel file\n",
    "library(writexl)\n",
    "write_xlsx(na_analysis, \"NA_threshold_analysis.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create an improved plot\n",
    "ggplot(na_analysis, aes(x = NA_Threshold)) +\n",
    "  geom_line(aes(y = Total_Rows, color = \"Total Rows\"), size = 1) +\n",
    "  geom_point(aes(y = Total_Rows, color = \"Total Rows\"), size = 3) +\n",
    "  geom_text(aes(y = Total_Rows, label = comma(Total_Rows)), \n",
    "            vjust = -0.5, size = 3, color = \"black\") +\n",
    "  geom_line(aes(y = Positive_Cases * (max(Total_Rows) / max(Positive_Cases)), \n",
    "                color = \"Positive Cases\"), size = 1) +\n",
    "  geom_point(aes(y = Positive_Cases * (max(Total_Rows) / max(Positive_Cases)), \n",
    "                 color = \"Positive Cases\"), size = 3) +\n",
    "  geom_text(aes(y = Positive_Cases * (max(Total_Rows) / max(Positive_Cases)), \n",
    "                label = comma(Positive_Cases)),\n",
    "            vjust = 1.5, size = 3, color = \"black\") +\n",
    "  scale_y_continuous(name = \"Total Rows\",\n",
    "                     sec.axis = sec_axis(~. * (max(na_analysis$Positive_Cases) / max(na_analysis$Total_Rows)), \n",
    "                                         name = \"Positive Cases\")) +\n",
    "  scale_color_manual(values = c(\"Total Rows\" = \"blue\", \"Positive Cases\" = \"red\")) +\n",
    "  labs(title = \"Impact of NA Threshold on Dataset Size\",\n",
    "       x = \"NA Threshold\",\n",
    "       color = \"Metric\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"bottom\",\n",
    "        axis.text.y.right = element_text(color = \"red\"),\n",
    "        axis.title.y.right = element_text(color = \"red\"))\n",
    "\n",
    "ggsave(\"HCC/NA_threshold_analysis_plot.png\", width = 10, height = 6, dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_nan <- read_xlsx(\"HCC/df_nan.xlsx\")\n",
    "df_y <- data.table::fread(\"HCC/HCC_case_controls.txt\", sep=\"\\t\") %>% \n",
    "  semi_join(df_nan, by = \"person_id\") %>%  rename(\"eid\" = \"person_id\")\n",
    "\n",
    "\n",
    "head(df_y)\n",
    "dim(df_y)\n",
    "sum(df_y$status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_covariates <- data.table::fread(\"HCC/HCC_covariates_1.7.txt\", sep=\"\\t\") %>% \n",
    "  semi_join(df_nan, by = \"person_id\") %>% select(-(c(\"AGE_cat\", \"BMI_cat\"))) %>% rename(\"eid\" = \"person_id\")\n",
    "df_covariates$SEX <- factor(df_covariates$SEX, levels = c(\"Female\", \"Male\"), labels = c(\"0\", \"1\"))\n",
    "df_covariates$'Ever smoked' <- factor(df_covariates$'Ever smoked', levels = c(\"No\", \"Yes\"), labels = c(\"0\", \"1\"))\n",
    "\n",
    "\n",
    "dim(df_covariates)\n",
    "head(df_covariates)\n",
    "\n",
    "covariates_list <- colnames(df_covariates)[-1]\n",
    "\n",
    "#check_missing_positives(df_covariates)\n",
    "str(df_covariates)\n",
    "summary(df_covariates)\n",
    "df_covariates <- impute_all(df_covariates)\n",
    "summarize_na(df_covariates)\n",
    "str(df_covariates)\n",
    "summary(df_covariates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut to physiol. limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mapper <- read_excel(\"HCC/Master_Table_JC.xlsx\", sheet = \"Mapper\")\n",
    "result <- limit_df(df_covariates, mapper)\n",
    "df_covariates <- result$df\n",
    "summary(df_covariates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_diagnosis <- data.table::fread(\"HCC/HCC_df_diagnosis.txt\", sep=\"\\t\") %>% \n",
    "  semi_join(df_nan, by = \"person_id\")%>% rename(\"eid\" = \"person_id\")\n",
    "\n",
    "dim(df_diagnosis)\n",
    "head(df_diagnosis)\n",
    "\n",
    "diagnosis_list <- colnames(df_diagnosis)[-1]\n",
    "\n",
    "\n",
    "diag_na <- summarize_na(df_diagnosis, rule=TRUE)\n",
    "print(diag_na)\n",
    "check_missing_positives(df_diagnosis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create df_blood - but include NAs for any missing lab values\n",
    "\n",
    "#lab_files <- data.table::fread(\"Jan/Blood_labs.txt\", header=F)$V1\n",
    "\n",
    "#df_blood <- data.frame(person_id = character(0))\n",
    "\n",
    "#for (filename in lab_files){\n",
    "#    lab_name <- strsplit(strsplit(filename, \"labs-\")[[1]][2], \"_normalized\")[[1]][1]\n",
    "#    labs <- data.table::fread(paste0(\"qc_labs/\",filename), sep=\"\\t\")\n",
    "#    labs <- labs %>%\n",
    "#        select(person_id, original_median) %>%\n",
    "#        rename(!!lab_name := original_median)\n",
    "#    df_blood <- merge(df_blood, labs, all=T)\n",
    "#}\n",
    "\n",
    "#write.table(df_blood, \"Jan/HCC_df_blood.txt\", sep=\"\\t\", quote=F, row.names=F)\n",
    "\n",
    "df_blood <- data.table::fread(\"HCC/HCC_df_blood.txt\", sep=\"\\t\") %>% \n",
    "  semi_join(df_nan, by = \"person_id\")%>% rename(\"eid\" = \"person_id\")\n",
    "\n",
    "df_blood <- map_and_align(df_blood, \"HCC/columnmapper_ukb_aou.xlsx\")\n",
    "\n",
    "dim(df_blood)\n",
    "head(df_blood)\n",
    "\n",
    "blood_list <- colnames(df_blood)[-1]\n",
    "df_blood <- impute_continuous(df_blood)\n",
    "summarize_na(df_blood)\n",
    "vec_blood <- setdiff(colnames(df_blood), \"eid\")\n",
    "vec_blood\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blood unit conversion and outlier adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "conversion_table <- read_xlsx(\"HCC/Master_Table_JC.xlsx\", sheet=\"Mapper\")\n",
    "df_blood <- convert_units(df_blood, conversion_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_blood_adjusted <- adjust_outlier_to_ukb(df_blood, conversion_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_summary_ukb <- read_xlsx(\"HCC/UKB_MinMax.xlsx\")\n",
    "#df_summary_ukb\n",
    "df_summary_aou_blood <- summarize_continuous_columns(df_blood_adjusted)\n",
    "#df_summary_aou_blood\n",
    "\n",
    "df_summary_blood <- inner_join(df_summary_ukb, df_summary_aou_blood, by= \"column\", suffix = c(\"_ukb\", \"_aou\")) %>%\n",
    "  select(column, sort(setdiff(names(.), \"column\")))\n",
    "df_summary_blood\n",
    "write_xlsx(df_summary_blood, \"HCC/df_summary_blood_ukb_aou.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check blood_nas individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_blood_y <- inner_join(df_blood, df_y, by = \"eid\") %>% filter(status == 1)\n",
    "\n",
    "dim(df_blood_y)\n",
    "head(df_blood_y)\n",
    "\n",
    "blood_na <- summarize_na(df_blood_y)\n",
    "print(blood_na)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_snp <- data.table::fread(\"HCC/HCC_SNPs.raw\", sep=\"\\t\")\n",
    "\n",
    "df_snp <- df_snp %>%\n",
    "    select(-FID, -PAT, -MAT, -SEX, -PHENOTYPE) %>%\n",
    "    rename(person_id = IID)\n",
    "\n",
    "dim(df_snp)\n",
    "head(df_snp)\n",
    "\n",
    "snp_list <- colnames(df_snp)[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "colnames(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge, normalize and save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_x_all_raw <- merge_dataframes(filter_par = FALSE)\n",
    "df_all <- df_x_all_raw %>% inner_join(df_y, by = \"eid\")  #Merge with HCC cases\n",
    "\n",
    "dim(df_all)\n",
    "head(df_all)\n",
    "colnames(df_all)\n",
    "# summarize_na(df_all)\n",
    "# summary(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "normalize_data_ukb <- function(df, conversion_table, vec_all) {\n",
    "  # Ensure the required columns exist in the conversion table\n",
    "  required_cols <- c(\"column\", \"max_ukb\")\n",
    "  if (!all(required_cols %in% colnames(conversion_table))) {\n",
    "    stop(\"Conversion table must contain 'column' and 'max_ukb' columns\")\n",
    "  }\n",
    "  \n",
    "  # Create a named vector of max_ukb values, converting to numeric\n",
    "  max_ukb_values <- sapply(setNames(conversion_table$max_ukb, conversion_table$column), \n",
    "                           function(x) as.numeric(as.character(x)))\n",
    "  \n",
    "  # Function to perform min-max normalization using UKB max\n",
    "  minmax_ukb <- function(x, max_ukb) {\n",
    "    if (is.na(max_ukb) || max_ukb == 0) {\n",
    "      warning(sprintf(\"Invalid max_ukb value for column. Skipping normalization.\"))\n",
    "      return(x)\n",
    "    }\n",
    "    return(x / max_ukb)\n",
    "  }\n",
    "  \n",
    "  # Iterate through each column in vec_all\n",
    "  for (col in vec_all) {\n",
    "    if (col %in% names(df) && col != \"eid\" && is.numeric(df[[col]])) {\n",
    "      if (col %in% names(max_ukb_values)) {\n",
    "        ukb_max <- max_ukb_values[col]\n",
    "        df[[col]] <- minmax_ukb(df[[col]], ukb_max)\n",
    "        cat(sprintf(\"Column '%s' normalized using UKB max: %s\\n\", \n",
    "                    col, format(ukb_max, scientific = FALSE)))\n",
    "      } else {\n",
    "        warning(sprintf(\"UKB max value not found for column '%s'. Skipping normalization.\", col))\n",
    "      }\n",
    "    } else if (col == \"eid\") {\n",
    "      cat(\"Column 'eid' skipped for normalization.\\n\")\n",
    "    } else if (!col %in% names(df)) {\n",
    "      warning(sprintf(\"Column '%s' not found in the dataframe\", col))\n",
    "    } else if (!is.numeric(df[[col]])) {\n",
    "      warning(sprintf(\"Column '%s' is not numeric. Skipping normalization.\", col))\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(df)\n",
    "}\n",
    "\n",
    "normalize_data_aou <- function(df, vec_covariates) {\n",
    "  # Function to perform standard min-max normalization\n",
    "  minmax <- function(x) {\n",
    "    if (length(unique(x)) == 1) return(x)  # Return as is if all values are the same\n",
    "    return((x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))\n",
    "  }\n",
    "  \n",
    "  # Iterate through each column in vec_covariates\n",
    "  for (col in vec_covariates) {\n",
    "    if (col %in% names(df) && col != \"eid\" && is.numeric(df[[col]])) {\n",
    "      df[[col]] <- minmax(df[[col]])\n",
    "      cat(sprintf(\"Column '%s' normalized using standard min-max.\\n\", col))\n",
    "    } else if (col == \"eid\") {\n",
    "      cat(\"Column 'eid' skipped for normalization.\\n\")\n",
    "    } else if (!col %in% names(df)) {\n",
    "      warning(sprintf(\"Column '%s' not found in the dataframe\", col))\n",
    "    } else if (!is.numeric(df[[col]])) {\n",
    "      warning(sprintf(\"Column '%s' is not numeric. Skipping normalization.\", col))\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(df)\n",
    "}\n",
    "                         \n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "vec_covariates <- c(\"MultipleDeprivationIndex\", \"Pack years\", \"Waist circumference\", # Columns for \"simple\" Minmax in covariates\n",
    "                  \"Weight\", \"Standing height\", \"Alk_g_d\", \"Bloodpressure_sys\", \"Bloodpressure_dia\", \"BMI\", \"AGE\")\n",
    "#vec_blood / vec_metabolomics are already defined above\n",
    "vec_all <- unique(c(vec_covariates, vec_blood)) \n",
    "vec_all\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_x_all_normalized <- normalize_data_ukb(df_all, conversion_table, vec_blood) %>%\n",
    "    normalize_data_aou(vec_covariates) %>%\n",
    "    select(-\"status\")\n",
    "    \n",
    "\n",
    "head(df_x_all_normalized)\n",
    "str(df_x_all_normalized)\n",
    "summary(df_x_all_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_y <- df_all %>% select(\"eid\", \"status\")\n",
    "head(df_y)\n",
    "str(df_y)\n",
    "sum(df_y$status)\n",
    "nrow(df_y) == nrow(df_x_all_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "col_subset <- \"basic\"\n",
    "subset_name <- \"all\"\n",
    "layer <- \"outer\"\n",
    "\n",
    "write.csv(df_x_all_normalized, file=paste(\"HCC/X_\", layer, \"_\", col_subset, \"_\", subset_name, \".csv\", sep=\"\"), row.names=FALSE)\n",
    "write.csv(df_y, file=paste(\"HCC/y_\", layer, \"_\", col_subset, \"_\", subset_name, \".csv\", sep=\"\"), row.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columngroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#install.packages(\"gtsummary\")\n",
    "#install.packages(\"flextable\")\n",
    "#install.packages(\"officer\")\n",
    "#remotes::install_version(\"glue\", version = \"1.8.0\")\n",
    "install.packages(\"cardx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(gtsummary)\n",
    "library(flextable)\n",
    "library(officer)\n",
    "library(cardx)\n",
    "library(gt)\n",
    "\n",
    "create_binary_list <- function(df) {\n",
    "    binary_cols <- sapply(df, function(x) all(x %in% c(0, 1)))\n",
    "    names <- names(df)[binary_cols]\n",
    "\n",
    "    return(names)\n",
    "}\n",
    "\n",
    "#Helper function to mask items with absolute < 20\n",
    "categorical_stat <- function(x) {\n",
    "    n <- sum(x == \"1\" | x == 1, na.rm = TRUE)\n",
    "    N <- sum(!is.na(x))\n",
    "    count_display <- if(n < 20) \"<20\" else as.character(n)\n",
    "    sprintf(\"%s (%.1f%%)\", count_display, n/N * 100)\n",
    "}                          \n",
    "                          \n",
    "                          \n",
    "# https://www.danieldsjoberg.com/gtsummary/articles/tbl_summary.html\n",
    "\n",
    "create_table <- function(df_tbl, table_name, table_name_prefix=\"All\", project_path=project_path, export_RDS=FALSE, head_only=FALSE, remove_SEX=TRUE, enforced_order=FALSE, biobank_key=biobank_key, create_binary_table=FALSE, adjust_p_values=TRUE, column_order = FALSE) {\n",
    "    project_path <- \"HCC\"\n",
    "    categorical_stat_fmt <- \"{n} ({p}%)\"\n",
    "  \n",
    "    if (remove_SEX) {\n",
    "        df_tbl <- df_tbl %>% select(-SEX)\n",
    "    }\n",
    "  \n",
    "    if (!isFALSE(enforced_order)) {\n",
    "        df_tbl <- df_tbl %>% select(status, all_of(enforced_order))\n",
    "    }\n",
    "  \n",
    "    if (isFALSE(enforced_order)) {\n",
    "        names <- sort(colnames(df_tbl))\n",
    "        df_tbl <- df_tbl %>% select(all_of(names)) \n",
    "    }\n",
    "  \n",
    "    if (head_only) {\n",
    "        df_tbl <- df_tbl %>% select(1:5, status)\n",
    "    }\n",
    "  \n",
    "    if (create_binary_table) {\n",
    "        names <- create_binary_list(df_tbl)\n",
    "        value_list <- lapply(names, function(name) {\n",
    "            formula <- as.formula(paste0(\"`\", name, \"` ~ '1'\"))\n",
    "            environment(formula) <- emptyenv()\n",
    "            return(formula)\n",
    "        })\n",
    "\n",
    "        label_list <- lapply(names, function(name) {\n",
    "            formula <- as.formula(paste0(\"`\", name, \"` ~ '\", name, \"'\"))\n",
    "            environment(formula) <- emptyenv()\n",
    "            return(formula)\n",
    "        })\n",
    "    } else {\n",
    "        value_list <- NULL\n",
    "    }\n",
    "  \n",
    "    if (!isFALSE(column_order)) {\n",
    "        df_tbl$status <- factor(df_tbl$status, levels = column_order)\n",
    "    }\n",
    "    \n",
    "    distinct_status_values <- df_tbl %>% distinct(status) %>% pull(status) %>% sort()\n",
    "  \n",
    "    continuous_columns <- c(\"Pack years\", \"Basophill (%)\", \"Eosinophill (%)\", \"Monocyte percentage\", \"Neutrophill count\", \"Total protein\")\n",
    "    continuous_columns_present <- continuous_columns[continuous_columns %in% colnames(df_tbl)]\n",
    "    type_list <- if (length(continuous_columns_present) > 0) {\n",
    "        lapply(continuous_columns_present, function(col) {\n",
    "            as.formula(paste0(\"`\", col, \"` ~ 'continuous'\"))\n",
    "        })\n",
    "    } else {\n",
    "        NULL\n",
    "    }\n",
    "  \n",
    "    \n",
    "    \n",
    "Table_gtsummary <- df_tbl %>%\n",
    "    tbl_summary(\n",
    "        by = status,\n",
    "        type = type_list,\n",
    "        value = value_list,\n",
    "        label = label_list,\n",
    "        statistic = list(\n",
    "            all_continuous() ~ \"{mean} (±{sd})\",\n",
    "            all_categorical() ~ categorical_stat_fmt\n",
    "        ),\n",
    "        digits = all_continuous() ~ 1,\n",
    "    ) %>%\n",
    "    add_overall() %>%\n",
    "    modify_table_body(\n",
    "            ~ .x %>%\n",
    "                mutate(\n",
    "                    across(starts_with(\"stat_\"), ~ case_when(\n",
    "                        # Mask counts <20 in categorical columns and remove percentage\n",
    "                        str_detect(., \"^\\\\d+,?\\\\d* \\\\(\") & \n",
    "                        as.numeric(gsub(\",\", \"\", str_extract(., \"^\\\\d+,?\\\\d*\"))) < 20 ~ \n",
    "                            str_replace(., \"^\\\\d+,?\\\\d* \\\\(.*?\\\\)\", \"<20\"),  # Removes count and percentage\n",
    "                        TRUE ~ .\n",
    "                    ))\n",
    "                )\n",
    "        ) %>%\n",
    "    add_p(\n",
    "        test = list(\n",
    "            all_continuous() ~ \"t.test\",\n",
    "            all_categorical() ~ \"chisq.test\"\n",
    "        )\n",
    "    ) %>%\n",
    "        \n",
    "        bold_labels() %>%\n",
    "        italicize_levels() %>%\n",
    "        bold_p() %>%\n",
    "        modify_header(update = list(\n",
    "            stat_0 ~ \"**Overall** \\n \\n N = {N}\",\n",
    "            !!sym(paste0(\"stat_\", 1)) ~ paste0(\"**\", distinct_status_values[1], \"** \\n\\n n = {n}\"),\n",
    "            !!sym(paste0(\"stat_\", 2)) ~ paste0(\"**\", distinct_status_values[2], \"** \\n\\n n = {n}\")\n",
    "        ), text_interpret = \"md\")\n",
    "  \n",
    "    if (adjust_p_values) {\n",
    "        Table_gtsummary <- Table_gtsummary %>%\n",
    "            add_q(method = \"bonferroni\")\n",
    "    }\n",
    "  \n",
    "    Table_gt <- as_gt(Table_gtsummary) %>%\n",
    "      fmt_number(\n",
    "          columns = c(-contains(\"p.value\"), -contains(\"q.value\")),  # Exclude p-value and q-value columns\n",
    "          decimals = 2,\n",
    "          locale = \"en\"  # Locale enforces '.' for decimals and ',' for thousands\n",
    "    )\n",
    "    print(Table_gt)\n",
    "  \n",
    "    if (export_RDS) {\n",
    "        saveRDS(Table_gtsummary, file = paste0(project_path, \"/tables/\", table_name, \".RDS\"))\n",
    "    }\n",
    "  \n",
    "    gt::gtsave(Table_gt, filename = paste0(project_path, \"/tables/\", table_name, \".html\"))\n",
    "  \n",
    "    #Table_gtsummary %>%\n",
    "     #   as_flex_table() %>%\n",
    "      #  save_as_docx(path = paste0(project_path, \"/tables/\", table_name, \"_\", biobank_key, \".docx\"))\n",
    "}\n",
    "     \n",
    "                          \n",
    "                          \n",
    "                          \n",
    "                          \n",
    "split_create_merge_tables <- function(df, feature, table_name, project_path, enforced_order=FALSE, head_only=FALSE, remove_SEX=TRUE, export_RDS=FALSE, create_binary_table = FALSE, adjust_p_values=TRUE) {\n",
    "    project_path <- \"HCC\"\n",
    "  \n",
    "    # Split the dataframe by the specified feature\n",
    "    split_dfs <- split(df, df[[feature]])\n",
    "  \n",
    "    if (!isFALSE(enforced_order)) {\n",
    "        enforced_order <- table1_order[table1_order != feature] #Remove feature to stratify from the order list\n",
    "    }\n",
    "  \n",
    "    # Iterate over each split dataframe\n",
    "    table_files <- c() # To store filenames of the saved tables for potential merging\n",
    "  \n",
    "    for (split_name in names(split_dfs)) {\n",
    "        # Define table name based on prefix and split name\n",
    "        merged_name <- paste(table_name, feature, split_name, sep=\"_\")\n",
    "        #table_files <- c(table_files, paste0(table_name, \"_\", Sys.Date(), \".RDS\"))\n",
    "\n",
    "        # Use create_table to generate and save each table\n",
    "    \n",
    "        create_table(df_tbl = split_dfs[[split_name]], \n",
    "                     table_name = merged_name, \n",
    "                     export_RDS = export_RDS, \n",
    "                     head_only = head_only, \n",
    "                     remove_SEX = remove_SEX, \n",
    "                     enforced_order = enforced_order,\n",
    "                     create_binary_table = create_binary_table,\n",
    "                     adjust_p_values = adjust_p_values)\n",
    "    }\n",
    "  \n",
    "    # Optionally merge the tables if more than one split\n",
    "    #if(export_RDS) {\n",
    "    #  tab_spanner <- names(split_dfs)\n",
    "    #  merge_saved_tables(table_files, project_path, tab_spanner)\n",
    "    #}\n",
    "\n",
    "    #gt::gtsave(Table_1_stratified, filename = paste0(project_path, \"/tables/Table_stratified\", table_name, \"_\", biobank_key, \"_\", Sys.Date(), \".html\"))\n",
    "}   \n",
    "                          \n",
    "                          \n",
    "                          \n",
    "import_merge_tables <- function(table_name, feature, levels,  tab_spanner) {\n",
    "    project_path <- \"HCC\"\n",
    "  \n",
    "    # Initialize an empty list to store the imported tables\n",
    "    imported_tables <- list()\n",
    "  \n",
    "    # Loop through each level and import the corresponding RDS file\n",
    "    for (level in levels) {\n",
    "        file_path <- paste0(project_path, \"/tables/\", table_name, \"_\", feature, \"_\", level, \".RDS\")\n",
    "        print(file_path)\n",
    "\n",
    "        imported_table <- readRDS(file_path)\n",
    "        #imported_table <- imported_table %>% filter(Variable != feature)\n",
    "        imported_tables[[level]] <- imported_table\n",
    "    }\n",
    "\n",
    "    # Merge the imported tables\n",
    "    merged_table <- tbl_merge(\n",
    "        tbls = imported_tables,\n",
    "        tab_spanner = levels\n",
    "    )\n",
    "    \n",
    "    print(merged_table)\n",
    "    merged_table <- as_gt(merged_table)\n",
    "    gt::gtsave(merged_table, filename = paste0(project_path, \"/tables/\", table_name, \"_\", feature, \".html\"))\n",
    "    # Return the merged table\n",
    "    return(merged_table)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define labels, orders, load additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "label_list <- list(\n",
    "  AGE = \"Age [years]\",\n",
    "  location_name = \"Location\",\n",
    "  location_country = \"Country\",\n",
    "  Family_diabetes = \"Family Diabetes\",\n",
    "  DM = \"Diabetes mellitus\",\n",
    "  Alk_g_d = \"Alcohol [g/d]\",\n",
    "  High_Alk = \"High Alcohol Consumption\",\n",
    "  Path_Alk = \"Pathological Alcohol Consumption\",\n",
    "  BMI_cat = \"BMI Categories\",\n",
    "  Bloodpressure_sys = \"Bloodpressure sys. [mmHg]\",\n",
    "  Weight = \"Weight [kg]\",\n",
    "  'Standing height' = \"Standing height [cm]\",\n",
    "  'Waist circumference' = \"Waist circumference [cm]\",\n",
    "  race_ethnicity = \"Self-reported ethnicity\"\n",
    ")\n",
    "\n",
    "table1_order <- c(\n",
    "  \"AGE\", \"SEX\", \"BMI\", \"Waist circumference\", \n",
    "  \"Weight\", \"Standing height\", \"race_ethnicity\", \n",
    "  \"MultipleDeprivationIndex\", \"Bloodpressure_sys\", \"Medication\", \"DM\",\n",
    "  \"Family_diabetes\", \"Pack years\", \"Alk_g_d\" # Continue as necessary\n",
    ")\n",
    "\n",
    "df_all <- df_x_all_raw %>% inner_join(df_y, by = \"eid\")\n",
    "df_ethnicity <- read_csv(\"HCC/df_ethnicity.csv\")\n",
    "\n",
    "df_all <- df_all %>% merge(df_ethnicity %>% select(eid, race_ethnicity), by = \"eid\") |>\n",
    "  mutate(\n",
    "    SEX = case_when(\n",
    "      SEX == \"0\" ~ \"Female\",\n",
    "      SEX == \"1\" ~ \"Male\",\n",
    "      .default = SEX\n",
    "    ),\n",
    "    status = case_when(\n",
    "      status == 0 ~ \"No HCC\",    # Removed quotes since status is numeric\n",
    "      status == 1 ~ \"HCC\",       # Removed quotes since status is numeric\n",
    "      .default = as.character(status)  # Convert to character for consistency\n",
    "    )\n",
    "  )\n",
    "\n",
    "nrow(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "colnames(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-stratified Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_tbl_1 <- df_all %>%\n",
    "  select(!any_of(c(blood_list, setdiff(diagnosis_list, \"DM\"), \"eid\", \"Date of assessment\")))\n",
    "  #elect(!any_of(c(blood_list, diagnosis_list, \"eid\", \"Date of assessment\", snp_list)))\n",
    "create_table(df_tbl_1, \"Table 1\", export_RDS=FALSE, head_only=FALSE, remove_SEX=FALSE,  enforced_order=table1_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_tbl_blood <- df_all %>%\n",
    "  select(any_of(c(\"status\", \"SEX\", blood_list)))\n",
    "\n",
    "create_table(df_tbl_blood, \"Table Blood\", export_RDS=FALSE, head_only=FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_tbl_icd <- df_all %>%\n",
    "  select(any_of(c(\"status\", \"SEX\", diagnosis_list)))\n",
    "\n",
    "# Remove codes with 0 cases\n",
    "#dim(df_tbl_icd)\n",
    "#missing_codes <- names(df_tbl_icd[,3:ncol(df_tbl_icd)])[colSums(df_tbl_icd[,3:ncol(df_tbl_icd)]) == 0]\n",
    "#print(missing_codes) #Dengue fever, oesophageal varices, yellow fever\n",
    "#df_tbl_icd <- df_tbl_icd %>% select(-any_of(missing_codes))\n",
    "#dim(df_tbl_icd)\n",
    "\n",
    "Table_ICD <- create_table(df_tbl_icd, \"Table ICD\", export_RDS=TRUE, head_only=FALSE, create_binary_table = FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_tbl_snp <- df_all %>%\n",
    "  select(any_of(c(\"status\", \"SEX\", snp_list)))\n",
    "\n",
    "create_table(df_tbl_snp, \"Table SNP\", export_RDS=FALSE, head_only=FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified tables (after sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Table 1 Sex-Stratified\n",
    "\n",
    "df_tbl_1 <- df_all %>%\n",
    "  select(!any_of(c(blood_list, setdiff(diagnosis_list, \"DM\"), \"eid\", \"Date of assessment\")))\n",
    "split_create_merge_tables(df_tbl_1, table_name=\"Table1\", feature=\"SEX\", enforced_order=table1_order, remove_SEX=TRUE, export_RDS=TRUE)\n",
    "Table_1_stratified <- import_merge_tables(table_name= \"Table1\", feature=\"SEX\", levels = c(\"Female\", \"Male\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Table ICD Sex-Stratified\n",
    "\n",
    "df_tbl_icd <- df_all %>%\n",
    "  select(any_of(c(\"status\", \"SEX\", diagnosis_list)))\n",
    "\n",
    "\n",
    "split_create_merge_tables(df_tbl_icd, table_name=\"Table_ICD\", feature=\"SEX\", enforced_order=FALSE, remove_SEX=TRUE, head_only=FALSE, export_RDS=TRUE)\n",
    "Table_ICD_stratified <- import_merge_tables(table_name= \"Table_ICD\", feature=\"SEX\", levels = c(\"Female\", \"Male\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Table Blood Sex-Stratified\n",
    "\n",
    "df_tbl_blood <- df_all %>%\n",
    "  select(any_of(c(\"status\", \"SEX\", blood_list)))\n",
    "\n",
    "\n",
    "split_create_merge_tables(df_tbl_blood, table_name=\"Table_Blood\", feature=\"SEX\", enforced_order=FALSE, remove_SEX=TRUE, head_only=FALSE, export_RDS=TRUE)\n",
    "Table_Blood_stratified <- import_merge_tables(table_name= \"Table_Blood\", feature=\"SEX\", levels = c(\"Female\", \"Male\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare AOU with UKB Predictions (only run this after modelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_tbl_TP <- df_all %>%\n",
    "  select(!any_of(c(blood_list, setdiff(diagnosis_list, c(\"DM\",\"Liver cirrhosis\")), \"Date of assessment\", \"status\", \"race_ethnicity\")))\n",
    "\n",
    "df_tbl_TP <- df_tbl_TP %>%\n",
    "    left_join(df_ethnicity %>% select(eid, ethnicity_ukb_aligned), by = \"eid\")\n",
    "\n",
    "\n",
    "col_subset <- \"Model_TOP15\"\n",
    "row_subset <- \"all\"\n",
    "\n",
    "pred_val <- read_excel(\"combined_output/val/Prediction_values_combined.xlsx\", sheet= paste0(row_subset, \"_\", col_subset))  #Change sheet as desired by changing col/row subset variables\n",
    "\n",
    "\n",
    "pred_val <- inner_join(pred_val, df_tbl_TP, by=\"eid\")\n",
    "\n",
    "pred_val <- pred_val %>% select(-(\"eid\"))\n",
    "\n",
    " \n",
    "\n",
    "#Define thresholds and create classes\n",
    "low_threshold <- 0.55\n",
    "\n",
    "pred_val <- pred_val %>%\n",
    "  mutate(\n",
    "    TP = if_else(status == 1 & y_pred > low_threshold, 1, 0),    #Add columns with TP TN etc each as boolean\n",
    "    TN = if_else(status == 0 & y_pred < low_threshold, 1, 0),\n",
    "    FP = if_else(status == 0 & y_pred > low_threshold, 1, 0),\n",
    "    FN = if_else(status == 1 & y_pred < low_threshold, 1, 0)\n",
    "  )\n",
    "\n",
    "pred_val <- pred_val %>%\n",
    "  mutate(status = case_when(\n",
    "      TP == 1 ~ \"TP\",\n",
    "      TN == 1 ~ \"TN\",\n",
    "      FP == 1 ~ \"FP\",\n",
    "      FN == 1 ~ \"FN\",\n",
    "      TRUE ~ NA_character_\n",
    "    )\n",
    "  )\n",
    "\n",
    "pred_val$Medication <- factor(pred_val$Medication, \n",
    "                               levels = sort(unique(pred_val$Medication)))\n",
    "\n",
    "pred_val <- pred_val %>%\n",
    "    mutate(ethnicity_ukb_aligned = factor(ethnicity_ukb_aligned,\n",
    "                                          levels = c(\"Asian\", \"Black\", \"Caucasian\", \"Latinx\", \"Other/Unknown\"))) %>%\n",
    "    rename(Ethnicity = ethnicity_ukb_aligned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pred_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "table_tp_order <- c(\n",
    "  \"y_pred\", \"AGE\", \"SEX\", \"Ethnicity\",  \"BMI\", \"Waist circumference\", \n",
    "  \"Weight\", \"Standing height\",\n",
    "  \"MultipleDeprivationIndex\", \"Bloodpressure_sys\", \"Medication\", \"DM\",\n",
    "  \"Family_diabetes\", \"Pack years\", \"Alk_g_d\", \"Liver cirrhosis\" # Continue as necessary\n",
    ")\n",
    "\n",
    "\n",
    "label_list <- list(\n",
    "  AGE = \"Age [years]\",\n",
    "  location_name = \"Location\",\n",
    "  location_country = \"Country\",\n",
    "  Family_diabetes = \"Family Diabetes\",\n",
    "  DM = \"Diabetes mellitus\",\n",
    "  Alk_g_d = \"Alcohol [g/d]\",\n",
    "  High_Alk = \"High Alcohol Consumption\",\n",
    "  Path_Alk = \"Pathological Alcohol Consumption\",\n",
    "  BMI_cat = \"BMI Categories\",\n",
    "  Bloodpressure_sys = \"Bloodpressure sys. [mmHg]\",\n",
    "  Weight = \"Weight [kg]\",\n",
    "  'Standing height' = \"Standing height [cm]\",\n",
    "  'Waist circumference' = \"Waist circumference [cm]\",\n",
    "  y_pred = \"Prediction Score\",\n",
    "  Alk_g_d = \"Alcohol [g/d]\",\n",
    "  Ethnicity = \"Ethnicity\"\n",
    ")\n",
    "\n",
    "head_only = FALSE\n",
    "\n",
    "table_name = paste0(\"All TP TN Options_threshold_\", low_threshold, \"_AOU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Create the TP FN Table for AOU and save as RDS\n",
    "create_table(pred_val, table_name, export_RDS=TRUE, head_only=FALSE, remove_SEX=FALSE,  enforced_order=table_tp_order, column_order = c(\"FN\", \"TP\", \"FP\", \"TN\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Function to merge the two RDS files\n",
    "## Make sure that not only the visible names align, but also the actual names of the underlying columns of the dataframe, otherwise this does not work (and the rows will be attached below)\n",
    "fuse_biobank_tables <- function(table_name, biobanks = c(\"UKB\", \"AOU\")) {\n",
    "  low_threshold <- get(\"low_threshold\", envir = .GlobalEnv)\n",
    "  \n",
    "  # Initialize an empty list to store the imported tables\n",
    "  imported_tables <- list()\n",
    "  \n",
    "  # Loop through each level and import the corresponding RDS file\n",
    "  for (biobank in biobanks) {\n",
    "    file_path <- paste0(\"HCC/tables/\", table_name, \"_\", low_threshold, \"_\", biobank, \".RDS\")\n",
    "    print(file_path)\n",
    "    \n",
    "    imported_table <- readRDS(file_path)\n",
    "    # Set the locale to ensure consistent number formatting\n",
    "    Sys.setlocale(\"LC_NUMERIC\", \"en_US.UTF-8\")\n",
    "    imported_tables[[biobank]] <- imported_table\n",
    "  }\n",
    "  \n",
    "  # Merge the tables with modified options\n",
    "  merged_table <- tbl_merge(\n",
    "    tbls = imported_tables,\n",
    "    tab_spanner = biobanks\n",
    "  )\n",
    "  \n",
    "  # First print the gtsummary object\n",
    "  print(merged_table)\n",
    "  \n",
    "  # Save as HTML using as_flex_table\n",
    "  html_path <- paste0(\"HCC/tables/\", table_name, \"_merged_\", paste(biobanks, collapse=\"_\"), \"_threshold_\", low_threshold, \".html\")\n",
    "  \n",
    "  # Try to save using flextable\n",
    "  merged_table_gt <- as_gt(merged_table)\n",
    "  gt::gtsave(merged_table_gt, filename = html_path)\n",
    "  \n",
    "  return(merged_table)\n",
    "}\n",
    "\n",
    "# Test the function\n",
    "Table_TPFN_stratified <- fuse_biobank_tables(\n",
    "  table_name = \"All TP TN Options_threshold\", \n",
    "  biobanks = c(\"UKB\", \"AOU\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New heading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create literature benchmark scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_early_cirrhosis <- read_csv(\"HCC/df_early_cirrhosis.csv\")\n",
    "\n",
    "df_early_cirrhosis <- df_early_cirrhosis %>%\n",
    "    rename(eid = person_id) %>%\n",
    "    merge(df_all %>% select(eid), by = c(\"eid\"), all=TRUE) %>%\n",
    "    mutate(cirrhosis = coalesce(cirrhosis, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AMAP Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_amap <- df_all %>%\n",
    "    select(c(\"eid\", \"SEX\", \"AGE\", \"Platelet count\", \"Albumin\", \"Total bilirubin\", \"status\")) %>%\n",
    "    rename(\n",
    "    bilirubin = `Total bilirubin`,\n",
    "    platelet_count = `Platelet count`,\n",
    "    albumin = `Albumin`\n",
    "  )\n",
    "\n",
    "df_amap$SEX <- as.character(df_amap$SEX)\n",
    "df_amap$SEX <- as.numeric(df_amap$SEX)\n",
    "\n",
    "summary(df_amap)\n",
    "df_amap$aMAP <- ((df_amap$AGE * 0.06 + df_amap$SEX * 0.89 + 0.48 * ((log10(df_amap$bilirubin) * 0.66) + (df_amap$albumin * -0.085)) - 0.01 * df_amap$platelet_count) + 7.4) / 14.77 * 100\n",
    "head(df_amap)\n",
    "df_amap <- df_amap %>% \n",
    "  select(c(\"eid\", \"aMAP\", \"SEX\", \"status\")) %>%\n",
    "  mutate(\n",
    "    aMAP = as.numeric(aMAP) / 100,  # Ensure numeric before division\n",
    "    aMAP = ifelse(is.infinite(aMAP), NA, aMAP)  # Replace Inf with NA\n",
    "  )\n",
    "summary(df_amap)\n",
    "\n",
    "df_amap <- df_amap %>%\n",
    "  mutate(\n",
    "  aMAP = as.numeric(round(aMAP, 3))\n",
    "  )  # Round to 2 decimal places)\n",
    "\n",
    "head(df_amap, 10)\n",
    "str(df_amap$'Total')\n",
    "summary(df_amap)\n",
    "write.csv(df_amap, file=paste(\"HCC/df_amap.csv\", sep=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fib-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_fib4 <- df_all %>% select(\"eid\", \"AGE\", AST = `Aspartate aminotransferase`,\n",
    "                     ALT = `Alanine aminotransferase`,\n",
    "                     PLT = `Platelet count`)\n",
    "\n",
    "df_fib4 <- df_fib4 %>%\n",
    "  mutate(\n",
    "    FIB4_orig = (AGE * AST) / (PLT * (ALT * 0.5))\n",
    "  )\n",
    "\n",
    "df_fib4 <- adjust_outliers(df_fib4, \"FIB4_orig\")\n",
    "\n",
    "\n",
    "# Calculate normalized FIB-4 score (0 to 1)\n",
    "df_fib4 <- df_fib4 %>%\n",
    "  mutate(\n",
    "    FIB4 = (FIB4_orig - min(FIB4_orig, na.rm = TRUE)) / (max(FIB4_orig, na.rm = TRUE) - min(FIB4_orig, na.rm = TRUE))\n",
    "  )\n",
    "head(df_fib4)\n",
    "sum(is.na(df_fib4$FIB4))\n",
    "summary(df_fib4)\n",
    "hist(df_fib4$FIB4_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_apri <- df_all %>% select(\"eid\", \"SEX\", AST = `Aspartate aminotransferase`,\n",
    "                     PLT = `Platelet count`)\n",
    "\n",
    "summary(df_apri)\n",
    "\n",
    "df_apri <- df_apri %>%\n",
    "  mutate(\n",
    "    ULN_AST = case_when(\n",
    "      SEX == \"0\" ~ 35,\n",
    "      SEX == \"1\" ~ 50,\n",
    "      TRUE ~ NA_real_\n",
    "    ),\n",
    "    APRI_orig = (AST / ULN_AST) / (PLT / 100)\n",
    "  )\n",
    "df_apri <- adjust_outliers(df_apri, \"APRI_orig\")\n",
    "summary(df_apri)\n",
    "\n",
    "# Normalize APRI score (0 to 1)\n",
    "df_apri <- df_apri %>%\n",
    "  mutate(\n",
    "    APRI = (APRI_orig - min(APRI_orig, na.rm = TRUE)) / (max(APRI_orig, na.rm = TRUE) - min(APRI_orig, na.rm = TRUE))\n",
    "  )\n",
    "\n",
    "# Summary of APRI scores\n",
    "summary(df_apri$APRI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NFS Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_nfs <- df_all %>% select(eid, SEX, BMI, AGE, DM, AST = `Aspartate aminotransferase`,\n",
    "                     ALT = `Alanine aminotransferase`,\n",
    "                     PLT = `Platelet count`,\n",
    "                    Albumin)\n",
    "\n",
    "df_nfs <- df_nfs %>%\n",
    "  mutate(\n",
    "    DM_numeric = as.numeric(DM),\n",
    "    AST_ALT_ratio = AST / ALT,\n",
    "    NFS_orig = -1.675 + 0.037 * AGE + 0.094 * BMI + 1.13 * ifelse(DM_numeric == 1, 1, 0) + \n",
    "          0.99 * AST_ALT_ratio - 0.013 * PLT - 0.66 * Albumin\n",
    "  )\n",
    "\n",
    "# Normalize NFS score (0 to 1)\n",
    "df_nfs <- df_nfs %>%\n",
    "  mutate(\n",
    "    NFS = (NFS_orig - min(NFS_orig, na.rm = TRUE)) / (max(NFS_orig, na.rm = TRUE) - min(NFS_orig, na.rm = TRUE))\n",
    "  )\n",
    "\n",
    "# Summary of NFS scores\n",
    "summary(df_nfs$NFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "check_zero_to_one <- function(x, column_name) {\n",
    "  if (!is.numeric(x)) {\n",
    "    cat(column_name, \"is not numeric.\\n\")\n",
    "    return(FALSE)\n",
    "  }\n",
    "  \n",
    "  values_in_range <- x >= 0 & x <= 1\n",
    "  all_in_range <- all(values_in_range, na.rm = TRUE)\n",
    "  \n",
    "  cat(column_name, \"check:\\n\")\n",
    "  cat(\"  All values between 0 and 1:\", all_in_range, \"\\n\")\n",
    "  cat(\"  Number of NA values:\", sum(is.na(x)), \"\\n\")\n",
    "  \n",
    "  if (!all_in_range) {\n",
    "    out_of_range <- x[!values_in_range & !is.na(x)]\n",
    "    cat(\"  Values out of range:\", out_of_range, \"\\n\")\n",
    "  }\n",
    "  \n",
    "  cat(\"\\n\")\n",
    "  return(all_in_range)\n",
    "}\n",
    "\n",
    "# Check \"status\" column\n",
    "status_check <- check_zero_to_one(df_amap$status, \"status\")\n",
    "\n",
    "# Check \"aMAP\" column\n",
    "amap_check <- check_zero_to_one(df_amap$aMAP, \"aMAP\")\n",
    "\n",
    "# Overall result\n",
    "if (status_check && amap_check) {\n",
    "  cat(\"Both 'status' and 'aMAP' columns contain only values between 0 and 1.\\n\")\n",
    "} else {\n",
    "  cat(\"At least one column contains values outside the range 0 to 1 or is not numeric.\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_benchmark <- df_amap %>%\n",
    "  select(eid, aMAP) %>%\n",
    "  inner_join(df_apri %>% select(eid, APRI), by = \"eid\") %>%\n",
    "  inner_join(df_fib4 %>% select(eid, FIB4), by = \"eid\") %>%\n",
    "  inner_join(df_nfs %>% select(eid, NFS), by = \"eid\") %>%\n",
    "  inner_join(df_early_cirrhosis, by = \"eid\")\n",
    "\n",
    "df_benchmark <- merge(df_benchmark, df_y, by=\"eid\")\n",
    "\n",
    "# Summary of the benchmark dataframe\n",
    "summary(df_benchmark)\n",
    "write.csv(df_benchmark, file=\"HCC/df_benchmark.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "493px",
    "width": "274px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "283.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
