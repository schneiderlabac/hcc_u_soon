{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.font_manager as fm\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "\n",
    "plt.rcParams['font.family'] = 'sans-serif' \n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans'] #change font to a known standard font"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the env\n",
    "\n",
    "path = \"/home/jupyter/workspaces/machinelearningforlivercancerriskprediction\"\n",
    "fig_path = f\"{path}/HCC/visuals\"\n",
    "auroc_path = f\"{fig_path}/AUROCs\"\n",
    "\n",
    "if not os.path.exists(auroc_path):\n",
    "    os.makedirs(auroc_path)\n",
    "\n",
    "\n",
    "#Define all possible scenarios and colors\n",
    "all_scenarios = {\n",
    "    'A': '#4995AD',\n",
    "    'B': '#385579',\n",
    "    'C': '#C13617',\n",
    "    'D': '#F0903E',\n",
    "    'E': '#F0C872',\n",
    "    'Demographics': '#4995AD',\n",
    "    'Diagnosis': '#385579',\n",
    "    'Blood': '#C13617',\n",
    "    'SNP': '#F0903E',\n",
    "    'Metabolomics': '#F0C872',\n",
    "    'Csmall': '#402155',\n",
    "    'AMAP-RFC': '#c9c9c9',\n",
    "    'TOP75' : '#cb6043',\n",
    "    'TOP30' : '#d1846e',\n",
    "    'TOP15' : '#d0a79a'\n",
    "}\n",
    "\n",
    "\n",
    "# 'Demographics': '#402155',\n",
    "# 'Diagnosis': '#1E477C',\n",
    "# 'Blood': '#21968C',\n",
    "# 'SNP': '#74E980',\n",
    "# 'Metabolomics': '#F8E61E'\n",
    "\n",
    "# Define different scenario lists (combinations of scenarios plotted together)\n",
    "scenario_lists = {\n",
    "    'incremental': ['A', 'B', 'C', 'D', 'E'],\n",
    "    'separate': ['Demographics', 'Diagnosis', 'Blood', 'SNP', 'Metabolomics'],\n",
    "    'small_prev': ['C', 'Csmall', 'AMAP-RFC'],\n",
    "    'small': ['AMAP-RFC', 'TOP75', 'TOP30', 'TOP15'],\n",
    "    'c': ['TOP75', 'TOP15'],\n",
    "    'all': list(all_scenarios.keys())\n",
    "}\n",
    "\n",
    "def get_colors(scenario_list):\n",
    "    return {scenario: all_scenarios[scenario] for scenario in scenario_list}\n",
    "\n",
    "\n",
    "def plot_colorbar(scenarios):\n",
    "    \"\"\"\n",
    "    Plots a colorbar based on the given scenarios.\n",
    "\n",
    "    Parameters:\n",
    "    - scenarios (list): A list of scenario labels.\n",
    "    \"\"\"\n",
    "    colors = get_colors(scenarios)\n",
    "    fig, ax = plt.subplots(figsize=(5.5, 1.1))\n",
    "    for i, (label, color) in enumerate(colors.items()):\n",
    "        rect = plt.Rectangle((i * 55, 0), 55, 55, linewidth=2, edgecolor='white', facecolor=color)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(i * 55 + 27.5, -10, label, ha='center', va='top', fontsize=10, color='black')\n",
    "    ax.set_xlim(0, len(scenarios) * 55)\n",
    "    ax.set_ylim(-20, 55)\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_roc_curve(test_scores, true_labels, ax=False, label=None, color='#c9c9c9', lw=2.5, linestyle=\"--\"):\n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, test_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_auc = round(roc_auc, 2)\n",
    "    base_fpr = np.linspace(0, 1, 100)\n",
    "    tpr = np.interp(base_fpr, fpr, tpr)\n",
    "\n",
    "    if label is None:\n",
    "        plot_label = 'aMAP ({:.2f})'.format(roc_auc)\n",
    "    else:\n",
    "        plot_label = '{} ({:.2f})'.format(label, roc_auc)\n",
    "\n",
    "    # Create the ROC curve plot\n",
    "    if ax == False:\n",
    "        plt.plot(base_fpr, tpr, color=color, lw=lw, label=plot_label, alpha=1, linestyle=linestyle)\n",
    "    else:\n",
    "        ax.plot(base_fpr, tpr, color=color, lw=lw, label=plot_label, alpha=1, linestyle=linestyle)\n",
    "    return thresholds, fpr, tpr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_rocs(tprs, fig, ax, plot_all=True, y_amap=None, col_line='b', scenario='', fill_bet=True, title='', fig_type='', n_splits=5, line_style='-'):\n",
    "    # Compute mean ROC curve and AUC\n",
    "    tprs = np.array(tprs)\n",
    "    mean_tprs = tprs.mean(axis=0)\n",
    "    std = tprs.std(axis=0)\n",
    "    base_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    tprs_upper = np.minimum(mean_tprs + std, 1)\n",
    "    tprs_lower = mean_tprs - std\n",
    "\n",
    "    # Plot ROC curves for each fold and mean ROC curve\n",
    "    if plot_all:\n",
    "        for i in range(n_splits):\n",
    "            ax.plot(base_fpr, tprs[i], 'b', alpha=0.3, lw=3)\n",
    "    ax.plot(base_fpr, mean_tprs, col_line, linestyle=line_style, label=f'{scenario} ({round(auc(base_fpr,mean_tprs),ndigits=2)})', lw=2.5)\n",
    "    if fill_bet:\n",
    "        ax.fill_between(base_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.3)\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], color=\"grey\", linestyle=\"--\", lw=2.5)\n",
    "    if y_amap is not None:\n",
    "        plot_roc_curve(test_scores=y_amap.amap, true_labels=y_amap.status, ax=ax)\n",
    "\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.0])\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=14)\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=14)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=13)\n",
    "    ax.set_title(title, fontsize=14, pad=10)\n",
    "    condensed_font = fm.FontProperties(family='sans-serif', style='normal', weight='normal', stretch='condensed')\n",
    "    ax.legend(loc=\"lower right\", bbox_to_anchor=(1.01, -0.02), fontsize=12, frameon=False, prop=condensed_font)\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "    # Export\n",
    "    if fig_type:\n",
    "        save_figure(fig, title, fig_type, fig_path)\n",
    "\n",
    "\n",
    "def plot_rocs_flexible(mapped_tprs, fig, ax, scenarios, cohort, plot_all=False, fill_bet=False, title='', fig_type='', n_splits=5):\n",
    "    colors = get_colors(scenarios)\n",
    "    for scenario in scenarios:\n",
    "        color = colors[scenario]\n",
    "        scenario_tprs = mapped_tprs.loc[(cohort, scenario), :]\n",
    "        plot_rocs(tprs=scenario_tprs.values, fig=fig, ax=ax, plot_all=plot_all,\n",
    "                  fill_bet=fill_bet, col_line=color, scenario=scenario,\n",
    "                  title=title, fig_type=fig_type, n_splits=n_splits)\n",
    "\n",
    "\n",
    "\n",
    "def plot_combined_roc(tprs1, tprs2, label1='amap_cld', label2='amap_all'):\n",
    "    \"\"\"\n",
    "    Plots two or more ROC curves in the same figure, currently used to compare the capacity of AMAP for different cohorts\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    mean_tpr1 = np.mean(tprs1, axis=0)\n",
    "    mean_tpr2 = np.mean(tprs2, axis=0)\n",
    "\n",
    "    ax.plot(mean_tpr1, label=label1)\n",
    "    ax.plot(mean_tpr2, label=label2)\n",
    "\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Combined ROC Curve')\n",
    "    ax.legend(loc='best', frameon=False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# def plot_rocs(tprs,fig, ax, plot_all=True,y_amap=None,col_line='b',scenario='',fill_bet=True, title='', fig_type='', n_splits=5, line_style='-'):\n",
    "#     # Compute mean ROC curve and AUC\n",
    "#     tprs = np.array(tprs)\n",
    "#     mean_tprs = tprs.mean(axis=0)\n",
    "#     std = tprs.std(axis=0)\n",
    "#     base_fpr=np.linspace(0, 1, 100)  # Create a range of fprs for the x\n",
    "\n",
    "#     tprs_upper = np.minimum(mean_tprs + std, 1)\n",
    "#     tprs_lower = mean_tprs - std\n",
    "\n",
    "#     # Plot ROC curves for each fold and mean ROC curve\n",
    "#     if plot_all==True:\n",
    "#         for i in range(n_splits):\n",
    "#             plt.plot(base_fpr, tprs[i], 'b', alpha=0.3, lw=3)\n",
    "#     plt.plot(base_fpr, mean_tprs, col_line, linestyle=line_style, label=f'{scenario} (AUC = {round(auc(base_fpr,mean_tprs),ndigits=3)})', lw=2.5)\n",
    "#     if fill_bet:\n",
    "#         plt.fill_between(base_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.3)\n",
    "\n",
    "\n",
    "#     plt.plot([0, 1], [0, 1],color=\"grey\", linestyle=\"--\", lw=2.5)\n",
    "#     if y_amap is not None:\n",
    "#         plot_roc_curve(test_scores=y_amap.amap,true_labels=y_amap.status)\n",
    "\n",
    "#     ax.set_xlim([0.0, 1.0])\n",
    "#     ax.set_ylim([0.0, 1.0])\n",
    "#     ax.set_xlabel('False Positive Rate', fontsize=14)\n",
    "#     ax.set_ylabel('True Positive Rate', fontsize=14)\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=13)\n",
    "#     ax.set_title(title, fontsize=16, pad=10)\n",
    "#     ax.legend(loc=\"lower right\", fontsize=12)\n",
    "#     plt.rcParams.update({'font.size': 16})  # Set a default font size for all elements\n",
    "\n",
    "#     #Export\n",
    "#     name = \"ROCs\"\n",
    "#     if fig_path:\n",
    "#         save_figure(fig, title, fig_type, fig_path)\n",
    "\n",
    "\n",
    "# def plot_combined_roc(tprs1, tprs2, label1='amap_cld', label2='amap_all'):\n",
    "#     \"\"\"\n",
    "#     Plots two or more ROC curves in the same figure, currently used to compare the capacity of AMAP for different cohorts\n",
    "\n",
    "#     Parameters:\n",
    "#     - tprs1: DataFrame or array-like, TPRs for the first data.\n",
    "#     - tprs2: DataFrame or array-like, TPRs for the second data.\n",
    "#     - label1: str, label for the first data.\n",
    "#     - label2: str, label for the second data.\n",
    "#     \"\"\"\n",
    "#     fig, ax = plt.subplots()\n",
    "#     mean_tpr1 = np.mean(tprs1, axis=0)\n",
    "#     mean_tpr2 = np.mean(tprs2, axis=0)\n",
    "\n",
    "#     ax.plot(mean_tpr1, label=label1)\n",
    "#     ax.plot(mean_tpr2, label=label2)\n",
    "\n",
    "#     ax.set_xlabel('False Positive Rate')\n",
    "#     ax.set_ylabel('True Positive Rate')\n",
    "#     ax.set_title('Combined ROC Curve')\n",
    "#     ax.legend(loc='best')\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# # Usage\n",
    "# # plot_combined_roc(tprs_amap_cld, tprs_amap_all)\n",
    "\n",
    "def save_figure(fig, title, fig_type, fig_path):\n",
    "    # Create necessary directories\n",
    "    os.makedirs(fig_path, exist_ok=True)\n",
    "\n",
    "    # Replace spaces and special characters in title for filename\n",
    "    file_name = title.replace(' ', '_').replace('/', '_')\n",
    "\n",
    "    # Construct file paths for PNG and SVG\n",
    "    #png_path = os.path.join(auroc_path, f\"{fig_type}_{file_name}_{model_type}.png\")\n",
    "    svg_path = os.path.join(auroc_path, f\"{fig_type}_{file_name}_{model_type}.svg\")\n",
    "\n",
    "\n",
    "    # Save the figure in both formats\n",
    "    #fig.savefig(png_path, format='png', dpi=300)\n",
    "    fig.savefig(svg_path, format='svg', transparent=True)\n",
    "\n",
    "\n",
    "plot_colorbar(scenario_lists['incremental'])\n",
    "plot_colorbar(scenario_lists['separate'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import single TPRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"RFC\"\n",
    "# import the tprs\n",
    "#tprs=pd.read_excel(path+'/Models/Pipelines/'+model_type+'/combined_output/val/TPRS_combined.xlsx')\n",
    "tprs=pd.read_excel(path+'/combined_output/val/TPRS_combined.xlsx')\n",
    "\n",
    "# import the amap data\n",
    "#amap_cld=pd.read_excel(path+'/Models/amaps_cld_all_with_y.xlsx')\n",
    "amap_all=pd.read_csv(path+'/HCC/df_amap.csv')\n",
    "benchmarks= pd.read_csv(path+'/HCC/df_benchmark.csv')\n",
    "# amap_cirrhosis=pd.read_csv(path+'/Models/df_amap_cirrhosis.csv')\n",
    "# amap_nafld=pd.read_csv(path+'/Models/df_amap_nafld.csv')\n",
    "# amap_par=pd.read_csv(path+'/Models/df_amap_par.csv')\n",
    "\n",
    "columns=tprs.columns.tolist()\n",
    "mapper=pd.DataFrame({'col_names':columns})\n",
    "mapper[\"estimator\"] = model_type\n",
    "mapper['cohort']=[i.split('_')[0] for i in mapper.col_names]\n",
    "mapper['scenario']=[i.split('_')[2] for i in mapper.col_names]\n",
    "mapper['model']=[i.split('_model')[1] for i in mapper.col_names]\n",
    "mapper.set_index('col_names',inplace=True)\n",
    "tprs.transpose()\n",
    "mapped_tprs=pd.concat([mapper,tprs.transpose()],axis=1).set_index(['cohort','scenario','model', 'estimator'])\n",
    "mapped_tprs.groupby(level=['cohort','scenario']).agg('mean').transpose()\n",
    "mapped_tprs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess aMAP for AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amap_all[\"aMAP\"] = amap_all[\"aMAP\"].apply(lambda x: x if 0 <= x <= 1 else pd.NA)\n",
    "amap_all = amap_all.dropna()\n",
    "amap_all['aMAP'] = pd.to_numeric(amap_all['aMAP'], errors='coerce')\n",
    "amap_all['status'] = pd.to_numeric(amap_all['status'], errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_impute = ['aMAP', 'NFS']\n",
    "\n",
    "# Impute the specified columns with their respective means\n",
    "for column in columns_to_impute:\n",
    "    benchmarks[column].fillna(benchmarks[column].mean(), inplace=True)\n",
    "\n",
    "# Verify the imputation\n",
    "print(\"NA counts after imputation:\")\n",
    "print(benchmarks[columns_to_impute].isnull().sum())\n",
    "\n",
    "# Optional: Display summary statistics of imputed columns\n",
    "print(\"\\nSummary of imputed columns:\")\n",
    "print(benchmarks[columns_to_impute].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "plot_roc_curve(test_scores=benchmarks[\"aMAP\"], true_labels=benchmarks.status, ax=ax, label=\"aMAP\", linestyle=\"-\")\n",
    "plot_roc_curve(test_scores=benchmarks[\"APRI\"], true_labels=benchmarks.status, ax=ax, label=\"APRI\", linestyle=\"--\")\n",
    "plot_roc_curve(test_scores=benchmarks[\"FIB4\"], true_labels=benchmarks.status, ax=ax, label=\"FIB4\", linestyle=\"-.\")\n",
    "plot_roc_curve(test_scores=benchmarks[\"NFS\"], true_labels=benchmarks.status, ax=ax, label=\"NFS\", linestyle=\":\")\n",
    "plot_roc_curve(test_scores=benchmarks[\"cirrhosis\"], true_labels=benchmarks.status, ax=ax, label=\"Cirrhosis\", linestyle=\"-\", color=\"#385579\")\n",
    "plot_rocs_flexible(mapped_tprs, fig, ax, scenario_lists['c'], 'all',\n",
    "                   title='Literature Benchmark (All Of Us)', fig_type=\"AUROCS_combined\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined AUROCs (Incremental) for one estimator class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "plot_roc_curve(test_scores=amap_par[\"aMAP\"], true_labels=amap_par.status, ax=ax)\n",
    "plot_rocs_flexible(mapped_tprs, fig, ax, scenario_lists['incremental'], 'par',\n",
    "                   title='Chronic Liver Disease', fig_type=\"AUROCS_combined\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "plot_roc_curve(test_scores=amap_all[\"aMAP\"], true_labels=amap_all.status, ax=ax)\n",
    "plot_rocs_flexible(mapped_tprs, fig, ax, scenario_lists['incremental'], 'all',\n",
    "                   title=\"All\", fig_type=\"AUROCS_combined\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separately trained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "plot_roc_curve(test_scores=amap_par[\"aMAP\"], true_labels=amap_par.status, ax=ax)\n",
    "plot_rocs_flexible(mapped_tprs, fig, ax, scenario_lists['separate'], 'par',\n",
    "                   title='Chronic Liver Disease', fig_type=\"AUROCS_separately\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "plot_roc_curve(test_scores=amap_all[\"aMAP\"], true_labels=amap_all.status, ax=ax)\n",
    "plot_rocs_flexible(mapped_tprs, fig, ax, scenario_lists['separate'], 'all',\n",
    "                   title='All', fig_type=\"AUROCS_separately\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(6, 5))\n",
    "# plot_roc_curve(test_scores=amap_all[\"aMAP\"], true_labels=amap_all.status, ax=ax)\n",
    "# plot_rocs_flexible(mapped_tprs, fig, ax, scenario_lists['small'], 'all',\n",
    "#                    title=\"All Patients - Small Models\", fig_type=\"AUROCS_small_models\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Small Models All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "plot_roc_curve(test_scores=amap_all[\"aMAP\"], true_labels=amap_all[\"status\"], ax=ax)\n",
    "plot_rocs_flexible(mapped_tprs, fig, ax, scenario_lists['small'], 'all',\n",
    "                   title=\"All Patients - Small Models\", fig_type=\"AUROCS_small_models\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small models PAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "#plot_roc_curve(test_scores=amap_par[\"aMAP\"], true_labels=amap_par.status, ax=ax)\n",
    "plot_rocs_flexible(mapped_tprs, fig, ax, scenario_lists['small'], 'par',\n",
    "                   title=\"Patients at Risk - Small Models\", fig_type=\"AUROCS_small_models\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For all 5 scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "\n",
    "# Loop through each scenario in the scenarios_colors dictionary\n",
    "for scenario, color in scenarios_colors.items():\n",
    "    fig, ax = plt.subplots()\n",
    "    plot_rocs(tprs=mapped_tprs.transpose()['cld', scenario].transpose(), col_line=color, scenario=scenario, plot_all=True, fill_bet=True, title=f'Chronic liver disease - Scenario {scenario}', fig_type=\"AUROC_sep\")\n",
    "\n",
    "for scenario, color in scenarios_colors.items():\n",
    "    fig_all, ax_all =plt.subplots()\n",
    "    plot_rocs(tprs=mapped_tprs.transpose()['all',scenario].transpose(),col_line=color,scenario=scenario,plot_all=True,fill_bet=True, title=f\"All - Scenario {scenario}\", fig_type=\"AUROC_sep\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax =plt.subplots()\n",
    "n_splits=5\n",
    "\n",
    "for scenario,color in zip(['A'],['#36617B']): #y, g, r, b, brown\n",
    "    plot_rocs(tprs=mapped_tprs.transpose()['par',scenario].transpose(),col_line=color,scenario=scenario,plot_all=True,fill_bet=True, title=f'Patients at Risk', fig_type=\"AUROC sep\")\n",
    "\n",
    "fig_all, ax_all =plt.subplots()\n",
    "n_splits=5\n",
    "for scenario,color in zip(['A'],['#36617B']):\n",
    "   plot_rocs(tprs=mapped_tprs.transpose()['all',scenario].transpose(),col_line=color,scenario=scenario,plot_all=False,fill_bet=False, title=\"All\", fig_type=\"AUROC_sep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing AMAP Subcohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing AMAP Subcohorts\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "#plot_roc_curve(test_scores=amap_cld.amap, true_labels=amap_cld.status, ax=ax, label=\"Chronic Liver Disease\", color=\"blue\", lw=1.5)\n",
    "plot_roc_curve(test_scores=amap_all[\"aMAP\"], true_labels=amap_all.status, ax=ax, label=\"All\", color=\"green\", lw=1.5)\n",
    "plot_roc_curve(test_scores=amap_par[\"aMAP\"], true_labels=amap_par.status, ax=ax, label=\"PAR\", color=\"green\", lw=1.5)\n",
    "#plot_roc_curve(test_scores=amap_cirrhosis.aMAP, true_labels=amap_cirrhosis.status, ax=ax, label=\"Cirrhosis\", color=\"red\", lw=1.5)\n",
    "#plot_roc_curve(test_scores=amap_nafld.aMAP, true_labels=amap_nafld.status, ax=ax, label=\"MASLD\", color=\"purple\", lw=1.5)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.plot([0, 1], [0, 1], color=\"grey\", linestyle=\"--\", lw=1)\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.tick_params(axis='both', which='major', labelsize=13)\n",
    "plt.title(\"AMAP Score For Different Groups at Risk\", fontsize=16)\n",
    "plt.legend(loc=\"lower right\", fontsize=12)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax =plt.subplots()\n",
    "n_splits=5\n",
    "\n",
    "for scenario,color in zip(['A'],['#36617B']): #y, g, r, b, brown\n",
    "    plot_rocs(tprs=mapped_tprs.transpose()['par',scenario].transpose(),col_line=color,scenario=scenario,plot_all=True,fill_bet=True, title=f'Patients at Risk', fig_type=\"AUROC sep\")\n",
    "\n",
    "fig_all, ax_all =plt.subplots()\n",
    "n_splits=5\n",
    "for scenario,color in zip(['A'],['#36617B']):\n",
    "   plot_rocs(tprs=mapped_tprs.transpose()['all',scenario].transpose(),col_line=color,scenario=scenario,plot_all=False,fill_bet=False, title=\"All\", fig_type=\"AUROC_sep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Estimators Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import multiple TPRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [\"XGB\", \"RFC\"]\n",
    "base_path = path + '/Models/Pipelines/'\n",
    "all_tprs = pd.DataFrame()\n",
    "\n",
    "for model_type in model_types:\n",
    "    # Construct path to the TPR file\n",
    "    tprs_path = f'{base_path}{model_type}/combined_output/val/TPRS_combined.xlsx'\n",
    "\n",
    "    # Load the TPRs\n",
    "    if os.path.exists(tprs_path):\n",
    "        tprs = pd.read_excel(tprs_path)\n",
    "        print(tprs.head)\n",
    "\n",
    "        columns=tprs.columns.tolist()\n",
    "        mapper=pd.DataFrame({'col_names':columns})\n",
    "        mapper[\"estimator\"] = model_type\n",
    "        mapper['cohort']=[i.split('_')[0] for i in mapper.col_names]\n",
    "        mapper['scenario']=[i.split('_')[2] for i in mapper.col_names]\n",
    "        mapper['model']=[i.split('_model')[1] for i in mapper.col_names]\n",
    "        mapper.set_index('col_names',inplace=True)\n",
    "        tprs.transpose()\n",
    "        mapped_tprs=pd.concat([mapper,tprs.transpose()],axis=1).set_index(['cohort','scenario','model', 'estimator'])\n",
    "        mapped_tprs.groupby(level=['cohort','scenario']).agg('mean').transpose()\n",
    "        mapped_tprs\n",
    "\n",
    "        # # Concatenate to the main DataFrame\n",
    "        all_tprs = pd.concat([all_tprs, mapped_tprs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark distinct estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "# Define cohorts to loop through\n",
    "cohorts = ['par']\n",
    "\n",
    "# Loop through each cohort\n",
    "for cohort in cohorts:\n",
    "    # Set up the plot for the current cohort\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))  # Adjust size as needed\n",
    "\n",
    "    # Loop through each scenario\n",
    "    for scenario, color in scenarios_colors_incremental.items():\n",
    "        # Loop through each estimator within the current scenario\n",
    "        for estimator in ['XGB', 'RFC']:  # Add other estimators as needed\n",
    "            # Extract TPRs for the current scenario, cohort, and estimator\n",
    "            scenario_tprs = all_tprs.loc[(cohort, scenario, slice(None), estimator), :]\n",
    "\n",
    "            line_style = \"--\" if estimator == 'XGB' else '-'\n",
    "\n",
    "\n",
    "            # Check if the scenario and estimator data is not empty\n",
    "            if not scenario_tprs.empty:\n",
    "                # Call plot_rocs function to plot the ROC curve\n",
    "                plot_rocs(tprs=scenario_tprs.values, fig=fig, ax=ax, plot_all=False, fill_bet=True, col_line=color, scenario=f'{scenario} - {estimator}', line_style=line_style, title=f'Estimator Benchmark - {cohort}', fig_type='AUROCS_combined', n_splits=n_splits)\n",
    "\n",
    "    # Finalize the plot settings\n",
    "    ax.set_title(f'AUROC Comparison by Scenario and Estimator for {cohort.upper()} Cohort')\n",
    "    ax.legend(title='Scenarios')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_structure(all_tprs, cohorts, scenarios, estimators):\n",
    "    print(\"Checking data structure...\")\n",
    "    print(f\"all_tprs shape: {all_tprs.shape}\")\n",
    "    print(f\"all_tprs index levels: {all_tprs.index.names}\")\n",
    "    print(f\"all_tprs columns: {all_tprs.columns}\")\n",
    "\n",
    "    # Check if cohorts, scenarios, and estimators exist in all_tprs\n",
    "    missing_cohorts = [cohort for cohort in cohorts if cohort not in all_tprs.index.get_level_values('cohort')]\n",
    "    missing_scenarios = [scenario for scenario in scenarios if scenario not in all_tprs.index.get_level_values('scenario')]\n",
    "    missing_estimators = [estimator for estimator in estimators if estimator not in all_tprs.index.get_level_values('estimator')]\n",
    "\n",
    "    if missing_cohorts:\n",
    "        print(f\"Error: Missing cohorts in all_tprs: {missing_cohorts}\")\n",
    "    if missing_scenarios:\n",
    "        print(f\"Error: Missing scenarios in all_tprs: {missing_scenarios}\")\n",
    "    if missing_estimators:\n",
    "        print(f\"Error: Missing estimators in all_tprs: {missing_estimators}\")\n",
    "\n",
    "def delong_roc_variance(tpr1, tpr2):\n",
    "    \"\"\"\n",
    "    Computes the variance for DeLong test using TPRs.\n",
    "    \"\"\"\n",
    "    n = len(tpr1)\n",
    "    v10 = np.var(tpr1)\n",
    "    v11 = np.var(tpr2)\n",
    "\n",
    "    # Estimate covariance\n",
    "    cov = np.cov(tpr1, tpr2)[0, 1]\n",
    "\n",
    "    return (v10 + v11 - 2 * cov) / n\n",
    "\n",
    "def delong_roc_test(tpr1, tpr2):\n",
    "    \"\"\"\n",
    "    Performs DeLong test using TPRs, accounting for multiple folds.\n",
    "    \"\"\"\n",
    "    # Assuming tpr1 and tpr2 are 2D arrays where each row is a fold\n",
    "    auc1 = np.mean(tpr1, axis=1)  # AUC for each fold\n",
    "    auc2 = np.mean(tpr2, axis=1)  # AUC for each fold\n",
    "\n",
    "    # Compute the differences in AUC for each fold\n",
    "    auc_diffs = auc1 - auc2\n",
    "\n",
    "    # Compute mean and standard error of the differences\n",
    "    mean_diff = np.mean(auc_diffs)\n",
    "    se_diff = np.std(auc_diffs, ddof=1) / np.sqrt(len(auc_diffs))\n",
    "\n",
    "    z = mean_diff / se_diff\n",
    "    p = 2 * (1 - stats.norm.cdf(abs(z))) # Two-sided test\n",
    "\n",
    "    return z, p, mean_diff, se_diff\n",
    "\n",
    "def perform_delong_test(all_tprs, cohorts, scenarios, estimators, compare_all=False, reference_scenario=None, reference_estimator=None):\n",
    "    check_data_structure(all_tprs, cohorts, scenarios, estimators)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for cohort in cohorts:\n",
    "        cohort_results = []\n",
    "\n",
    "        if compare_all:\n",
    "            # Compare all scenarios with each other\n",
    "            scenario_pairs = list(combinations(scenarios, 2))\n",
    "        else:\n",
    "            # Compare only with the reference scenario\n",
    "            if reference_scenario is None or reference_estimator is None:\n",
    "                raise ValueError(\"reference_scenario and reference_estimator must be provided when compare_all is False\")\n",
    "            scenario_pairs = [(reference_scenario, scenario) for scenario in scenarios if scenario != reference_scenario]\n",
    "\n",
    "        for scenario1, scenario2 in scenario_pairs:\n",
    "            for estimator in estimators:\n",
    "                tpr1 = all_tprs.loc[(cohort, scenario1, slice(None), estimator), :].values\n",
    "                tpr2 = all_tprs.loc[(cohort, scenario2, slice(None), estimator), :].values\n",
    "\n",
    "                # Perform DeLong's test\n",
    "                z, p_value, mean_diff, se_diff = delong_roc_test(tpr1, tpr2)\n",
    "\n",
    "                cohort_results.append({\n",
    "                    'Estimator' : f\"{estimator}\",\n",
    "                    'Model1': f\"{scenario1}\",\n",
    "                    'Model2': f\"{scenario2}\",\n",
    "                    'Z-statistic': np.round(z, 4),\n",
    "                    'p-value': (p_value),\n",
    "                    'Mean AUC Difference': round(mean_diff, 4),\n",
    "                    'SE of Difference': round(se_diff, 4)\n",
    "                })\n",
    "\n",
    "        # Create DataFrame for the cohort\n",
    "        results[cohort] = pd.DataFrame(cohort_results)\n",
    "\n",
    "        # Apply Bonferroni correction\n",
    "        n_tests = len(results[cohort])\n",
    "        results[cohort]['Bonferroni-adjusted p-value'] = np.minimum(results[cohort]['p-value'] * n_tests, 1.0)\n",
    "\n",
    "        # Determine significance after Bonferroni correction\n",
    "        results[cohort]['Significant (α=0.05)'] = results[cohort]['Bonferroni-adjusted p-value'] < 0.05\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong_results_all = perform_delong_test(\n",
    "    all_tprs=mapped_tprs,\n",
    "    cohorts=['all'],\n",
    "    scenarios=['TOP75', 'TOP30', 'TOP15', 'AMAP-RFC'],\n",
    "    estimators=['RFC'],\n",
    "    compare_all=True\n",
    ")\n",
    "\n",
    "\n",
    "def save_results_to_excel(results, file_name):\n",
    "    with pd.ExcelWriter(file_name) as writer:\n",
    "        for cohort, df in results.items():\n",
    "            df.to_excel(writer, sheet_name=cohort, index=False)\n",
    "\n",
    "save_results_to_excel(delong_results_all, f\"{path}/HCC/tables/delong_test_results_all.xlsx\")\n",
    "\n",
    "\n",
    "# Print results\n",
    "for result_type, delong_results in [(\"All Comparisons\", delong_results_all)]:\n",
    "    print(f\"\\n--- {result_type} ---\")\n",
    "    for cohort, results in delong_results.items():\n",
    "        print(f\"\\nDeLong Test Results for {cohort}:\")\n",
    "        print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
